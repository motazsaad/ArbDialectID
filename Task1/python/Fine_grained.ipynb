{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier, RidgeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_tokenize(tweet):\n",
    "    return tweet.split(' ')\n",
    "\n",
    "def skipgram_tokenize(tweet, n=None, k=None, include_all=True):\n",
    "    from nltk.util import skipgrams\n",
    "    tokens = [w for w in basic_tokenize(tweet)]\n",
    "    if include_all:\n",
    "        result = []\n",
    "        for i in range(k+1):\n",
    "            skg = [w for w in skipgrams(tokens, n, i)]\n",
    "            result = result+skg\n",
    "    else:\n",
    "        result = [w for w in skipgrams(tokens, n, k)]\n",
    "    result=set(result)\n",
    "    #print(result)\n",
    "    return result\n",
    "\n",
    "def make_skip_tokenize(n, k, include_all=True):\n",
    "    return lambda tweet: skipgram_tokenize(tweet, n=n, k=k, include_all=include_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_estimators():\n",
    "    estimators = []\n",
    "    sgd = SGDClassifier(alpha=0.00001, max_iter=50,penalty=\"l2\") \n",
    "    estimators.append(('sgd', sgd))\n",
    "    svc = LinearSVC(penalty='l2', dual=False,tol=1e-3)\n",
    "    estimators.append(('svc',svc))\n",
    "    mnb= MultinomialNB(alpha=.01)\n",
    "    estimators.append(('mnb',mnb))\n",
    "    bnb= BernoulliNB(alpha=.01)\n",
    "    estimators.append(('bnb',bnb))\n",
    "    ensemble = VotingClassifier(estimators)\n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MADAR dataset for categories:\n",
      "['BEI', 'CAI', 'DOH', 'MSA', 'RAB', 'TUN']\n",
      "Traing Data:   41606\n",
      "Testing Data:   5007\n",
      "6 categories\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_file = '../data/D6_26/6dialects/train_small'  #'../data/Dialect6/Multi_data/train/post_clean'#  \n",
    "#test_file = '../data/Dialect6/Multi_data/dev/post_clean'\n",
    "#test_file = '../data/Dialect26/Multi_data/dev/post_clean'\n",
    "test_file = '../data/D6_26/6dialects/dev'\n",
    "\n",
    "print(\"Loading MADAR dataset for categories:\")\n",
    "data_train = load_files(train_file, encoding = 'utf-8',decode_error='ignore')\n",
    "data_test = load_files(test_file, encoding = 'utf-8',decode_error='ignore')\n",
    "y_train = data_train.target\n",
    "y_test = data_test.target\n",
    "print(data_train.target_names)\n",
    "target_names = data_train.target_names\n",
    "print(\"Traing Data:   {0}\".format(len(data_train.data)))\n",
    "print(\"Testing Data:   {0}\".format(len(data_test.data)))\n",
    "print(\"%d categories\" % len(target_names))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from the training data using a sparse vectorizer\n",
      "Combined space has 599530 features\n",
      "accuracy:   0.821\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BEI       0.84      0.87      0.85      1201\n",
      "         CAI       0.83      0.84      0.84       801\n",
      "         DOH       0.81      0.78      0.79      1201\n",
      "         MSA       0.76      0.74      0.75       601\n",
      "         RAB       0.93      0.85      0.89       601\n",
      "         TUN       0.76      0.85      0.80       602\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      5007\n",
      "   macro avg       0.82      0.82      0.82      5007\n",
      "weighted avg       0.82      0.82      0.82      5007\n",
      "\n",
      "confusion matrix:\n",
      "[[1040   39   72   15    4   31]\n",
      " [  47  675   26   22    2   29]\n",
      " [  83   54  933   70   12   49]\n",
      " [  32   21   78  444   10   16]\n",
      " [  14    8   13   22  511   33]\n",
      " [  28   13   28   11   13  509]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting features from the training data using a sparse vectorizer\")\n",
    "\n",
    "union = FeatureUnion([(\"w_v\", TfidfVectorizer(sublinear_tf=True, max_df=0.5,analyzer = 'word', ngram_range=(1,2))),\n",
    "                       (\"c_wb\", TfidfVectorizer(sublinear_tf=True, max_df=0.5,analyzer = 'char', ngram_range=(2,5))),\n",
    "                        (\"sk\",TfidfVectorizer(sublinear_tf=True, max_df=0.5,tokenizer=make_skip_tokenize(n=2, k=2)))\n",
    "        ],\n",
    "transformer_weights={\n",
    "            'w_v': 0.5,\n",
    "            'c_wb': 0.5,\n",
    "            'sk': 0.4,\n",
    "        }\n",
    ",\n",
    ")\n",
    "X_train = union.fit_transform(data_train.data)\n",
    "X_test = union.transform(data_test.data)\n",
    "print(\"Combined space has\", X_train.shape[1], \"features\")\n",
    "\n",
    "ensemble = build_estimators()\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "pred = ensemble.predict(X_test)\n",
    "#for i in range(0,10):\n",
    " #   print(data_train.target_names[pred[i]])\n",
    "\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "print(\"classification report:\")\n",
    "print(metrics.classification_report(y_test, pred,target_names=target_names))\n",
    "\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BEI', 'CAI', 'DOH', 'MSA', 'RAB', 'TUN']\n"
     ]
    }
   ],
   "source": [
    "train_files = []\n",
    "test_files = []\n",
    "data_trains = []\n",
    "data_tests = []\n",
    "\n",
    "print(data_train.target_names)\n",
    "for target in data_train.target_names:\n",
    "    train_files.append('../data/D6_26/6dialects/splited_train/'+ target)\n",
    "    test_files.append('../data/D6_26/6dialects/splited_dev/'+target)\n",
    "    data_trains.append(load_files(train_files[-1], encoding = 'utf-8',decode_error='ignore'))\n",
    "    data_tests.append(load_files(test_files[-1], encoding = 'utf-8',decode_error='ignore'))\n",
    "\n",
    "#for i,target in enumerate(data_train.target_names):\n",
    " #   print(\"Traing Data:   {0} {1}\".format(len(data_trains[i].data),target))\n",
    "\n",
    "#for i in range(0,len(data_train.target_names)):\n",
    "       # print(len(data_trains[i].data))\n",
    "#print(data_train.target_names[pre]+'\\t'+data_test.target_names[target])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_union(wv,cwb,ch,sk,i):\n",
    "    if i == 0 :\n",
    "        union = FeatureUnion([(\"w_v\", TfidfVectorizer(sublinear_tf=True, max_df=0.7,analyzer = 'word', ngram_range=(1,4)\n",
    "                                     )),\n",
    "                           (\"c_wb\", TfidfVectorizer(sublinear_tf=True, max_df=0.7,analyzer = 'char_wb', ngram_range=(2,5)\n",
    "                                     )),\n",
    "                           (\"ch\", TfidfVectorizer(sublinear_tf=True, max_df=0.7,analyzer = 'char', ngram_range=(2,4)\n",
    "                                     )),\n",
    "          (\"sk\",TfidfVectorizer(sublinear_tf=True, max_df=0.7,tokenizer=make_skip_tokenize(n=2, k=1)))\n",
    "                           ],\n",
    "    transformer_weights={\n",
    "                'w_v': 0.5,\n",
    "                'c_wb': cwb,\n",
    "               ' ch':ch,\n",
    "                'sk': sk,\n",
    "            }\n",
    "    ,\n",
    "    )\n",
    "    elif i == 1 : #CAI\n",
    "        union = FeatureUnion([(\"w_v\", TfidfVectorizer(sublinear_tf=True, max_df=0.5,analyzer = 'word', ngram_range=(1,3)\n",
    "                                     )),\n",
    "                           (\"c_wb\", TfidfVectorizer(sublinear_tf=True, max_df=0.5,analyzer = 'char_wb', ngram_range=(2,5)\n",
    "                                     )),\n",
    "                           (\"ch\", TfidfVectorizer(sublinear_tf=True, max_df=0.5,analyzer = 'char', ngram_range=(2,4)\n",
    "                                     )),\n",
    "          (\"sk\",TfidfVectorizer(sublinear_tf=True, max_df=0.5,tokenizer=make_skip_tokenize(n=2, k=2)))\n",
    "                           ],\n",
    "    transformer_weights={\n",
    "                'w_v': wv,\n",
    "                'c_wb': cwb,\n",
    "               ' ch':0.7,\n",
    "                'sk': sk,\n",
    "            }\n",
    "    ,\n",
    "    )\n",
    "    elif i == 3 :\n",
    "        union = FeatureUnion([(\"w_v\", TfidfVectorizer(sublinear_tf=True, max_df=0.5,analyzer = 'word', ngram_range=(1,2)\n",
    "                                     )),\n",
    "                           (\"c_wb\", TfidfVectorizer(sublinear_tf=True, max_df=0.5,analyzer = 'char_wb', ngram_range=(2,5)\n",
    "                                     )),\n",
    "                           (\"ch\", TfidfVectorizer(sublinear_tf=True, max_df=0.5,analyzer = 'char', ngram_range=(2,4)\n",
    "                                     )),\n",
    "          (\"sk\",TfidfVectorizer(sublinear_tf=True, max_df=0.5,tokenizer=make_skip_tokenize(n=2, k=1)))\n",
    "                           ],\n",
    "    transformer_weights={\n",
    "                'w_v': wv,\n",
    "                'c_wb': cwb,\n",
    "               ' ch':ch,\n",
    "                'sk': sk,\n",
    "            }\n",
    "    ,\n",
    "    )\n",
    "    elif i == 4:\n",
    "        union = FeatureUnion([(\"w_v\", TfidfVectorizer(sublinear_tf=True, max_df=0.5,analyzer = 'word', ngram_range=(1,3)\n",
    "                                     )),\n",
    "                           (\"c_wb\", TfidfVectorizer(sublinear_tf=True, max_df=0.5,analyzer = 'char_wb', ngram_range=(2,5)\n",
    "                                     )),\n",
    "                           (\"ch\", TfidfVectorizer(sublinear_tf=True, max_df=0.5,analyzer = 'char', ngram_range=(2,6)\n",
    "                                     )),\n",
    "          (\"sk\",TfidfVectorizer(sublinear_tf=True, max_df=0.5,tokenizer=make_skip_tokenize(n=2, k=1)))\n",
    "                           ],\n",
    "    transformer_weights={\n",
    "                'w_v': wv,\n",
    "                'c_wb': 0.7,\n",
    "               ' ch':0.7,\n",
    "                'sk': sk,\n",
    "            }\n",
    "    ,\n",
    "    )\n",
    "    elif i == 5:\n",
    "        union = FeatureUnion([(\"w_v\", TfidfVectorizer(sublinear_tf=True, max_df=0.5,analyzer = 'word', ngram_range=(1,2)\n",
    "                                     )),\n",
    "                           (\"c_wb\", TfidfVectorizer(sublinear_tf=True, max_df=0.5,analyzer = 'char_wb', ngram_range=(2,5)\n",
    "                                     )),\n",
    "                          # (\"ch\", TfidfVectorizer(sublinear_tf=True, max_df=0.5,analyzer = 'char', ngram_range=(2,6)\n",
    "                                   #  )),\n",
    "          (\"sk\",TfidfVectorizer(sublinear_tf=True, max_df=0.5,tokenizer=make_skip_tokenize(n=2, k=1)))\n",
    "                           ],\n",
    "    transformer_weights={\n",
    "                'w_v': wv,\n",
    "                'c_wb': 0.7,\n",
    "               #' ch':0.2,\n",
    "                'sk': sk,\n",
    "            }\n",
    "    ,\n",
    "    )\n",
    "    elif i == 2 :\n",
    "        union = FeatureUnion([(\"w_v\", TfidfVectorizer(sublinear_tf=True, max_df=0.5,analyzer = 'word', ngram_range=(1,3)\n",
    "                                     )),\n",
    "                           (\"c_wb\", TfidfVectorizer(sublinear_tf=True, max_df=0.5,analyzer = 'char_wb', ngram_range=(2,5)\n",
    "                                     )),\n",
    "                           (\"ch\", TfidfVectorizer(sublinear_tf=True, max_df=0.5,analyzer = 'char', ngram_range=(2,4)\n",
    "                                     )),\n",
    "          (\"sk\",TfidfVectorizer(sublinear_tf=True, max_df=0.5,tokenizer=make_skip_tokenize(n=2, k=1)))\n",
    "                           ],\n",
    "    transformer_weights={\n",
    "                'w_v': 0.7,\n",
    "                'c_wb': 0.7,\n",
    "               ' ch':0.7,\n",
    "                'sk': 0.4,\n",
    "            }\n",
    "    ,\n",
    "    )\n",
    "    else:\n",
    "        union = FeatureUnion([(\"w_v\", TfidfVectorizer(sublinear_tf=True, max_df=0.5,analyzer = 'word', ngram_range=(1,4)\n",
    "                                     )),\n",
    "                           (\"c_wb\", TfidfVectorizer(sublinear_tf=True, max_df=0.5,analyzer = 'char_wb', ngram_range=(2,5)\n",
    "                                     )),\n",
    "                           (\"ch\", TfidfVectorizer(sublinear_tf=True, max_df=0.5,analyzer = 'char', ngram_range=(2,4)\n",
    "                                     )),\n",
    "          (\"sk\",TfidfVectorizer(sublinear_tf=True, max_df=0.5,tokenizer=make_skip_tokenize(n=2, k=1)))\n",
    "                           ],\n",
    "        transformer_weights={\n",
    "                'w_v': wv,\n",
    "                'c_wb': cwb,\n",
    "               ' ch':ch,\n",
    "                'sk': sk,\n",
    "            }\n",
    "        ,\n",
    "        )\n",
    "    \n",
    "    return union\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEI\n",
      "['ALE', 'AMM', 'BEI', 'DAM', 'JER', 'SAL']\n",
      "Traing Data:   9600\n",
      "6 categories\n",
      "Combined space has 200827 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xabuka/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy:   0.612\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ALE       0.63      0.71      0.67       200\n",
      "         AMM       0.57      0.67      0.62       200\n",
      "         BEI       0.67      0.70      0.69       200\n",
      "         DAM       0.63      0.56      0.59       200\n",
      "         JER       0.54      0.61      0.57       200\n",
      "         SAL       0.65      0.43      0.52       200\n",
      "\n",
      "   micro avg       0.61      0.61      0.61      1200\n",
      "   macro avg       0.62      0.61      0.61      1200\n",
      "weighted avg       0.62      0.61      0.61      1200\n",
      "\n",
      "confusion matrix:\n",
      "[[142   8  19  13  12   6]\n",
      " [ 13 133   7  11  25  11]\n",
      " [ 22   8 140  16  10   4]\n",
      " [ 24  26  17 111  11  11]\n",
      " [ 13  28  10  12 122  15]\n",
      " [ 10  29  15  12  48  86]]\n",
      "CAI\n",
      "['ALX', 'ASW', 'CAI', 'KHA']\n",
      "Traing Data:   6400\n",
      "4 categories\n",
      "Combined space has 160722 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xabuka/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy:   0.635\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ALX       0.54      0.62      0.58       200\n",
      "         ASW       0.57      0.61      0.59       200\n",
      "         CAI       0.57      0.47      0.52       200\n",
      "         KHA       0.89      0.83      0.86       200\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       800\n",
      "   macro avg       0.64      0.64      0.64       800\n",
      "weighted avg       0.64      0.64      0.64       800\n",
      "\n",
      "confusion matrix:\n",
      "[[124  40  30   6]\n",
      " [ 47 123  26   4]\n",
      " [ 50  44  95  11]\n",
      " [  9   8  17 166]]\n",
      "DOH\n",
      "['BAG', 'BAS', 'DOH', 'JED', 'MOS', 'RIY']\n",
      "Traing Data:   9600\n",
      "6 categories\n",
      "Combined space has 195983 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xabuka/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy:   0.740\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BAG       0.65      0.72      0.69       200\n",
      "         BAS       0.60      0.68      0.64       200\n",
      "         DOH       0.76      0.76      0.76       200\n",
      "         JED       0.80      0.77      0.78       200\n",
      "         MOS       0.85      0.82      0.84       200\n",
      "         RIY       0.81      0.69      0.74       200\n",
      "\n",
      "   micro avg       0.74      0.74      0.74      1200\n",
      "   macro avg       0.75      0.74      0.74      1200\n",
      "weighted avg       0.75      0.74      0.74      1200\n",
      "\n",
      "confusion matrix:\n",
      "[[145  40   3   5   3   4]\n",
      " [ 45 136   8   3   6   2]\n",
      " [  6  13 152  12   4  13]\n",
      " [  9  12  12 153   3  11]\n",
      " [  8  16   8   1 165   2]\n",
      " [  9   8  17  17  12 137]]\n",
      "MSA\n",
      "['MSA', 'MUS', 'SAN']\n",
      "Traing Data:   4800\n",
      "3 categories\n",
      "Combined space has 123566 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xabuka/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy:   0.845\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         MSA       0.80      0.94      0.86       200\n",
      "         MUS       0.84      0.74      0.79       200\n",
      "         SAN       0.91      0.85      0.88       200\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       600\n",
      "   macro avg       0.85      0.85      0.84       600\n",
      "weighted avg       0.85      0.84      0.84       600\n",
      "\n",
      "confusion matrix:\n",
      "[[187  10   3]\n",
      " [ 38 149  13]\n",
      " [ 10  19 171]]\n",
      "RAB\n",
      "['ALG', 'FES', 'RAB']\n",
      "Traing Data:   4800\n",
      "3 categories\n",
      "Combined space has 244041 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xabuka/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy:   0.817\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ALG       0.85      0.93      0.89       200\n",
      "         FES       0.77      0.80      0.78       200\n",
      "         RAB       0.83      0.72      0.77       200\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       600\n",
      "   macro avg       0.82      0.82      0.81       600\n",
      "weighted avg       0.82      0.82      0.81       600\n",
      "\n",
      "confusion matrix:\n",
      "[[186   8   6]\n",
      " [ 17 160  23]\n",
      " [ 16  40 144]]\n",
      "TUN\n",
      "['BEN', 'SFX', 'TRI', 'TUN']\n",
      "Traing Data:   6400\n",
      "4 categories\n",
      "Combined space has 110323 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xabuka/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy:   0.791\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BEN       0.78      0.92      0.84       200\n",
      "         SFX       0.72      0.83      0.77       200\n",
      "         TRI       0.85      0.76      0.80       200\n",
      "         TUN       0.85      0.66      0.74       200\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       800\n",
      "   macro avg       0.80      0.79      0.79       800\n",
      "weighted avg       0.80      0.79      0.79       800\n",
      "\n",
      "confusion matrix:\n",
      "[[183   3  13   1]\n",
      " [  9 166   7  18]\n",
      " [ 34  10 152   4]\n",
      " [  9  52   7 132]]\n"
     ]
    }
   ],
   "source": [
    "#build 5 models for all sub categories \n",
    "#start fine_grained\n",
    "ensembles,union_fine = [],[]\n",
    "#data_trains = []\n",
    "for i in range(0,len(data_train.target_names)):\n",
    "    #print(data_trains[i].target_names)\n",
    "    \"\"\"if i == 3: #there is only one class here MSA.\n",
    "        union_fine.append(0)\n",
    "        ensembles.append(0)\n",
    "        continue\"\"\"\n",
    "    #i=0\n",
    "    print(data_train.target_names[i])\n",
    "    y_train_fine = data_trains[i].target\n",
    "    print(data_trains[i].target_names)\n",
    "    target_names_fine = data_trains[i].target_names\n",
    "    print(\"Traing Data:   {0}\".format(len(data_trains[i].data)))\n",
    "    print(\"%d categories\" % len(target_names_fine))\n",
    "    union_fine.append(feature_union(0.5,0.5,0.5,0.4,i))\n",
    "    X_train_fine = union_fine[-1].fit_transform(data_trains[i].data) #union.fit_transform(data_train.data)\n",
    "    print(\"Combined space has\", X_train_fine.shape[1], \"features\")\n",
    "    ensembles.append(build_estimators().fit(X_train_fine, y_train_fine))\n",
    "    print()\n",
    "    X_test = union_fine[-1].transform(data_tests[i].data)\n",
    "    pred = ensembles[-1].predict(X_test)\n",
    "#for i in range(0,10):\n",
    " #   print(data_train.target_names[pred[i]])\n",
    "    y_test = data_tests[i].target\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "    print(\"classification report:\")\n",
    "    print(metrics.classification_report(y_test, pred,target_names=data_tests[i].target_names))\n",
    "\n",
    "    print(\"confusion matrix:\")\n",
    "    print(metrics.confusion_matrix(y_test, pred))\n",
    "    #break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_test_file =  open('result26/voting_gold_1.txt','w+') \n",
    "pred_test_file = open('result26/voting_pred_1.txt','w+')\n",
    "sample_file = open('result26/voting_test_set_1.txt','w+')\n",
    "test_file26 = '../data/Dialect26/Multi_data/dev/new_clean'\n",
    "data_test = load_files(test_file26, encoding = 'utf-8',decode_error='ignore')\n",
    "X_test = union.transform(data_test.data)\n",
    "y_test = data_test.target\n",
    "pred = ensemble.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JER\tALE\t بدي ياك تاخدني علي محلات ممتعه انا سايح بتعرف\n",
      "\n",
      "\n",
      "TUN\tBEI\t نسيت مشروباتنا\n",
      "\n",
      "\n",
      "SAN\tDAM\t معي مكينتي\n",
      "\n",
      "\n",
      "AMM\tSAL\t بقدر ادفع عن طريق شيك سياحي\n",
      "\n",
      "\n",
      "ALE\tBEI\t بدي كريم ايد\n",
      "\n",
      "\n",
      "SAL\tJER\t بدي كريم ايدين\n",
      "\n",
      "\n",
      "RIY\tJER\t بنتقاسم\n",
      "\n",
      "\n",
      "BEI\tJER\t خلينا نحضر تلفزيون في مبارات باسكتبول\n",
      "\n",
      "\n",
      "SAN\tAMM\t كم بتكلف الليموزين لوسط المدينه\n",
      "\n",
      "\n",
      "ALE\tJER\t بدي كريم ليلي\n",
      "\n",
      "\n",
      "ALE\tDAM\t بتستقبلني هالليله\n",
      "\n",
      "\n",
      "CAI\tALE\t تلاتين دولار تمانين سنت\n",
      "\n",
      "\n",
      "BAS\tAMM\t علي اي جهه من يونيون سكوير هو\n",
      "\n",
      "\n",
      "ALE\tAMM\t بيجي هاد مع قسم السلطه واختيار من البطاطا المخبوزه او البطاطا المقليه\n",
      "\n",
      "\n",
      "SAL\tAMM\t انا معك وحده من الاماكن المفضله عندي\n",
      "\n",
      "\n",
      "MSA\tAMM\t دعنا نشاهد التلفزيون فيها مباراه بيسبول\n",
      "\n",
      "\n",
      "MOS\tALE\t شكرا مرحبا شكرا لانتضارك\n",
      "\n",
      "\n",
      "JER\tBEI\t بدي ضو\n",
      "\n",
      "\n",
      "KHA\tSAL\t من احجز غرفه دبل بتطل علي المحيط\n",
      "\n",
      "\n",
      "TRI\tJER\t همم هدا اللون يطلع حلو عليك\n",
      "\n",
      "\n",
      "SAL\tBEI\t المجموع طابه وحده و عصايتين\n",
      "\n",
      "\n",
      "AMM\tJER\t جلد التمساح\n",
      "\n",
      "\n",
      "DOH\tSAL\t السيفون ما ينسحب\n",
      "\n",
      "\n",
      "ALE\tBEI\t حاس حالي بردان وبطني عم توجعني كتير\n",
      "\n",
      "\n",
      "BEI\tDAM\t شو هالموسيقي\n",
      "\n",
      "\n",
      "ALG\tBEI\t عندي اختين\n",
      "\n",
      "\n",
      "ALE\tJER\t كاميرا الفيديو انسرقت من غرفتي\n",
      "\n",
      "\n",
      "DOH\tBEI\t عندي اختين\n",
      "\n",
      "\n",
      "JER\tAMM\t اسمي كيمورا بدي الغي حجزي ليوم الجمعه\n",
      "\n",
      "\n",
      "SAL\tALE\t همم هاد اللون طالع حلو عليك\n",
      "\n",
      "\n",
      "DAM\tBEI\t عندي اختين\n",
      "\n",
      "\n",
      "DAM\tAMM\t قول مره تانيه لو سمحت\n",
      "\n",
      "\n",
      "SAL\tBEI\t فرجيني وحده اوسع\n",
      "\n",
      "\n",
      "JER\tDAM\t حمام الاعشاب و الملح بيخلي جلدك يصير ناعم و سلس\n",
      "\n",
      "\n",
      "FES\tALE\t فينا جانب من يونيون سكوير هو\n",
      "\n",
      "\n",
      "TRI\tAMM\t الشارع كان معبي بسيارات\n",
      "\n",
      "\n",
      "SAN\tAMM\t الغرفه بتكلف سته الف ين بالليله\n",
      "\n",
      "\n",
      "SAL\tJER\t بتقدر تحكيلي وين بلاقي القنصليه اليابانيه\n",
      "\n",
      "\n",
      "ASW\tDAM\t نبيت تاني لو سمحت\n",
      "\n",
      "\n",
      "BEI\tSAL\t نمت خلال الارم السته و نص\n",
      "\n",
      "\n",
      "JER\tBEI\t اكيد بدك كيرلي\n",
      "\n",
      "\n",
      "BEI\tALE\t رقم الرحله هو اتش بي تسعه وتمانين لطوكيو ب حداعش اذار\n",
      "\n",
      "\n",
      "BEN\tSAL\t لو سمحت صرف شيك مسافر\n",
      "\n",
      "\n",
      "TRI\tAMM\t في اي جهه من يونيون سكوير موجود\n",
      "\n",
      "\n",
      "BEI\tJER\t ما عندي لا عصا ولا بوط\n",
      "\n",
      "\n",
      "DAM\tAMM\t يا في كتير اشياء لازم تشوفها بغرينيش فيليج\n",
      "\n",
      "\n",
      "AMM\tALE\t عندك واحد اكبر\n",
      "\n",
      "\n",
      "SAL\tAMM\t بدي كرسي كويس\n",
      "\n",
      "\n",
      "BEI\tJER\t لازم لحق طياره العشره الصبح\n",
      "\n",
      "\n",
      "RAB\tJER\t خلصت اصلا عربون بخمسين دولار منين جيت\n",
      "\n",
      "\n",
      "RIY\tJER\t ملح لو سمحت\n",
      "\n",
      "\n",
      "DOH\tDAM\t يصير اعزمك علي العشا برع مره من المرات\n",
      "\n",
      "\n",
      "SAL\tAMM\t بدي اياك تاخدني لاماكن مثيره انا ساءح زي ما بتعرف\n",
      "\n",
      "\n",
      "DAM\tAMM\t بدي نفس صنف الاكل بكري لو سمحت\n",
      "\n",
      "\n",
      "ALG\tALE\t اذا قطار مباشر\n",
      "\n",
      "\n",
      "CAI\tALE\t مج قهوه كبير اذا سمحت\n",
      "\n",
      "\n",
      "BEI\tDAM\t لاء هني كتير متينين\n",
      "\n",
      "\n",
      "MSA\tBEI\t انا جاهز صباح الاربعاء او بعد ظهر الجمعه\n",
      "\n",
      "\n",
      "SAL\tJER\t بتقدر توصل اغراصي للغرفه\n",
      "\n",
      "\n",
      "BEI\tDAM\t شو لازم تدفع ضريبه اذا بدك تشتري اكتر من تلت قناني الكول\n",
      "\n",
      "\n",
      "SAN\tAMM\t لو سمحت اصرف الشيك السياحي\n",
      "\n",
      "\n",
      "SAL\tAMM\t بدي كاسه مي حتي اخد الدوا لو سمحت\n",
      "\n",
      "\n",
      "AMM\tJER\t مش عم بقدر انام منيح بالليل\n",
      "\n",
      "\n",
      "AMM\tDAM\t تشاركني بفنجان قهوه\n",
      "\n",
      "\n",
      "SAL\tJER\t شو رقم امين الصندوق\n",
      "\n",
      "\n",
      "BAS\tALE\t عندك واحد اكبر\n",
      "\n",
      "\n",
      "BEN\tDAM\t حمام الاعشاب و الاملاح يخلي جلدتك ملمسها ناعم و سلس\n",
      "\n",
      "\n",
      "ASW\tAMM\t دقايق لو سمحت\n",
      "\n",
      "\n",
      "DAM\tALE\t غرفتك بتطل عالمدينه\n",
      "\n",
      "\n",
      "JED\tJER\t مسجل الفيديو انسرع من غرفتي\n",
      "\n",
      "\n",
      "BEI\tAMM\t عنا حوالي التلاتين نوع من زيوت الحمام\n",
      "\n",
      "\n",
      "SAL\tAMM\t وهيك عملت\n",
      "\n",
      "\n",
      "MOS\tAMM\t عندي معداتي الخاصه\n",
      "\n",
      "\n",
      "RIY\tJER\t خمسين جنيه\n",
      "\n",
      "\n",
      "BEI\tAMM\t كرسه الحمام مش عم بتطلع مي\n",
      "\n",
      "\n",
      "SAL\tAMM\t من وين بقدر اشتري بكرج\n",
      "\n",
      "\n",
      "SAL\tDAM\t ما في مشكله\n",
      "\n",
      "\n",
      "ASW\tJER\t خمسين جنيه\n",
      "\n",
      "\n",
      "DAM\tJER\t في ناس انصابوا\n",
      "\n",
      "\n",
      "BEI\tALE\t وانا كمان\n",
      "\n",
      "\n",
      "JER\tAMM\t لو سمحت ساعدني الاقي مرشد بحكي ياباني\n",
      "\n",
      "\n",
      "AMM\tBEI\t دايما بكون عليك تشتغل بالليل\n",
      "\n",
      "\n",
      "SAL\tJER\t بقدر اعزمكو مره علي العشا\n",
      "\n",
      "\n",
      "BEI\tALE\t اعلنو الطلعه عالطياره\n",
      "\n",
      "\n",
      "ALE\tAMM\t عفوا وين صايره المحطه هون\n",
      "\n",
      "\n",
      "JER\tAMM\t يمكن بس لازم نوزنهم كل واحد لحال\n",
      "\n",
      "\n",
      "ALE\tDAM\t مكتب الاستقبال كيف فيني اساعدك\n",
      "\n",
      "\n",
      "JER\tAMM\t العدد طابه وحده و ضربتين\n",
      "\n",
      "\n",
      "ALE\tBEI\t كتير مهم انو نوصل للمواد الاوليه يلي بتلزمنا للمشروع\n",
      "\n",
      "\n",
      "AMM\tALE\t بدي جاكيتات رياضه\n",
      "\n",
      "\n",
      "AMM\tSAL\t من عشره لطنعش لو سمحت\n",
      "\n",
      "\n",
      "ASW\tDAM\t فنجان قهوه لو سمحت\n",
      "\n",
      "\n",
      "BEI\tJER\t بدي لمبه\n",
      "\n",
      "\n",
      "SAL\tJER\t ما في اشي طلع من الجهاز\n",
      "\n",
      "\n",
      "AMM\tSAL\t تنزلني عندك الليله\n",
      "\n",
      "\n",
      "SAL\tBEI\t طيب هلا خلينا نتفرج عليك\n",
      "\n",
      "\n",
      "RIY\tJER\t عندك اكبر\n",
      "\n",
      "\n",
      "BEI\tALE\t بدك الطاوله بالمطعم الرءيسي او بغرفه خاصه استاذ\n",
      "\n",
      "\n",
      "DAM\tAMM\t هاد قطار مباشر\n",
      "\n",
      "\n",
      "RIY\tJER\t نمت عن منبه الساعه سته و نص\n",
      "\n",
      "\n",
      "DAM\tJER\t معك موظف التليفون الخارجي\n",
      "\n",
      "\n",
      "DAM\tALE\t املاح الحمام العشبيه بتساوي بشرتك رقيقه وناعمه\n",
      "\n",
      "\n",
      "SAL\tBEI\t ما في دفع ضروري\n",
      "\n",
      "\n",
      "DAM\tAMM\t لفهن كل واحد لحال لو سمحت\n",
      "\n",
      "\n",
      "BEI\tALE\t عندك واحد اكبر\n",
      "\n",
      "\n",
      "DAM\tSAL\t دوله قهوه لو سمحت\n",
      "\n",
      "\n",
      "BEI\tALE\t بفتح الاربعا الصبح والجمعه بعد الضهر\n",
      "\n",
      "\n",
      "SAL\tAMM\t بدي نفس الدوره بكرا لو سمحت\n",
      "\n",
      "\n",
      "SAL\tBEI\t عندي اختين\n",
      "\n",
      "\n",
      "SAL\tJER\t اعبر الجسر من هناك و رح تلاقي المكتبه علي جهه ايدك الشمال\n",
      "\n",
      "\n",
      "SAL\tBEI\t يمكن بس لازم نوزنهم منفصلين\n",
      "\n",
      "\n",
      "JER\tALE\t في عندك كمان واحد\n",
      "\n",
      "\n",
      "CAI\tALE\t عايز ا خد نفس التدريب بكره اذا سمحت\n",
      "\n",
      "\n",
      "SAL\tAMM\t في اشي بقدر اعمله عشان هاي العجقه\n",
      "\n",
      "\n",
      "SAN\tALE\t السياره بتطلع اصوات غريبه\n",
      "\n",
      "\n",
      "AMM\tJER\t شو رقم الكاشير\n",
      "\n",
      "\n",
      "BEN\tAMM\t تقدر تخصم منه لعند العشرين دولار لو سمحت\n",
      "\n",
      "\n",
      "SAL\tAMM\t علي اي جهه من يونيون سكوير\n",
      "\n",
      "\n",
      "SAL\tBEI\t عندي دوا\n",
      "\n",
      "\n",
      "AMM\tDAM\t بدي شويه دفاتر\n",
      "\n",
      "\n",
      "JER\tDAM\t طلبته من زمان\n",
      "\n",
      "\n",
      "SAL\tDAM\t رح نتشارك\n",
      "\n",
      "\n",
      "JER\tDAM\t رح اخد تنتين من هدول\n",
      "\n",
      "\n",
      "DAM\tAMM\t عبي طلب التسجيل هاد لو سمحت\n",
      "\n",
      "\n",
      "SAL\tALE\t حاس بضيق بالصدر\n",
      "\n",
      "\n",
      "DAM\tBEI\t حاس حالي بردان ومعدتي عم توجعني كتير\n",
      "\n",
      "\n",
      "ALE\tAMM\t بدي شويه ورق مسوده\n",
      "\n",
      "\n",
      "FES\tJER\t خمسين جنيه\n",
      "\n",
      "\n",
      "JER\tSAL\t شو هاي الموسيقي\n",
      "\n",
      "\n",
      "SAL\tJER\t بتقدر ترنلي الصبح بكير لو سمحت\n",
      "\n",
      "\n",
      "JER\tBEI\t انا بردان و معدتي بتوجع كتير\n",
      "\n",
      "\n",
      "KHA\tBEI\t عندي اختين\n",
      "\n",
      "\n",
      "JER\tAMM\t ما بفهم امريكي انا بحكي انجليزي بريطاني\n",
      "\n",
      "\n",
      "KHA\tAMM\t انا ما بقدر انوم كويس بالليل\n",
      "\n",
      "\n",
      "CAI\tALE\t اذا سمحت من عشره لتناشر\n",
      "\n",
      "\n",
      "ALE\tBEI\t اكيد بدك كيرلي\n",
      "\n",
      "\n",
      "ALG\tBEI\t سبق و خلصت الضمانه بخمسين دولار غير وصلت\n",
      "\n",
      "\n",
      "DAM\tALE\t رح نضل هون يوم\n",
      "\n",
      "\n",
      "BEN\tSAL\t كيف لازم تدفع ضريبه لما يكون عندك اكثر من ثلاث شيش كحول\n",
      "\n",
      "\n",
      "DAM\tSAL\t من العشره للطنعش لو سمحت\n",
      "\n",
      "\n",
      "JER\tDAM\t رح نتشارك\n",
      "\n",
      "\n",
      "BEN\tDAM\t عاود لو سمحت\n",
      "\n",
      "\n",
      "JER\tALE\t هي هويتي\n",
      "\n",
      "\n",
      "ASW\tDAM\t هي الجوله اليوم كله\n",
      "\n",
      "\n",
      "DAM\tALE\t وانا كمان\n",
      "\n",
      "\n",
      "JER\tAMM\t بدي كاسه مي عشان اخد الدوا لو سمحت\n",
      "\n",
      "\n",
      "RIY\tJER\t خارجه عن السيطره تقدر تفحص كاميرتي\n",
      "\n",
      "\n",
      "TUN\tBEI\t عندك واحد ما اكبر\n",
      "\n",
      "\n",
      "BEN\tBEI\t دجاج محمر لو سمحت\n",
      "\n",
      "\n",
      "RAB\tBEI\t تلاتين دولار و تمانين سنت\n",
      "\n",
      "\n",
      "BEI\tDAM\t ما في شي طلع من المكنه\n",
      "\n",
      "\n",
      "SAL\tAMM\t مش لاقيهم باي مكان\n",
      "\n",
      "\n",
      "ALX\tJER\t لازم الحق طيران عشره الصبح\n",
      "\n",
      "\n",
      "BEN\tJER\t ملح لو سمحت\n",
      "\n",
      "\n",
      "JED\tDAM\t خلينا نتابع التلفزون فيه مباراه بيسبول\n",
      "\n",
      "\n",
      "BEI\tALE\t ما عم نام منيح بالليل\n",
      "\n",
      "\n",
      "ALE\tSAL\t رح نشارك\n",
      "\n",
      "\n",
      "SAN\tAMM\t غرفتك مطله علي المدينه\n",
      "\n",
      "\n",
      "AMM\tJER\t غرفتك بتطل علي المدينه\n",
      "\n",
      "\n",
      "BEI\tDAM\t حاس مطربق فوق عصدري\n",
      "\n",
      "\n",
      "BEI\tDAM\t اديش كان في بالبو\n",
      "\n",
      "\n",
      "SAL\tJER\t بتقدر تخصم لعشرين دولار لو سمحت\n",
      "\n",
      "\n",
      "JED\tALE\t تلاتين دولار وتمانين سنت\n",
      "\n",
      "\n",
      "JER\tSAL\t عفوا بس ضيعت الطريق بتقدر تساعدني\n",
      "\n",
      "\n",
      "ASW\tBEI\t تلاتين دولار و تمانين سنت\n",
      "\n",
      "\n",
      "RAB\tJER\t كلشي جا بتمنيه و تلاتين دولار\n",
      "\n",
      "\n",
      "JER\tAMM\t بدي اسطوانه طباعه\n",
      "\n",
      "\n",
      "TRI\tALE\t عندك واحد اكبر\n",
      "\n",
      "\n",
      "JED\tALE\t دي بطاقه الهويه\n",
      "\n",
      "\n",
      "JER\tBEI\t في محطه بنزين بعد بلوكتين من هون\n",
      "\n",
      "\n",
      "JED\tALE\t الحمامات العشبيه تخلي بشرتك تحس بالنعومه\n",
      "\n",
      "\n",
      "KHA\tAMM\t الحمام ما بدفق\n",
      "\n",
      "\n",
      "ALE\tDAM\t عندي دوا خاص فيني\n",
      "\n",
      "\n",
      "ALX\tALE\t القطورات وقفت بسبب الاضراب\n",
      "\n",
      "\n",
      "MUS\tJER\t جلد التمساح\n",
      "\n",
      "\n",
      "BEI\tSAL\t لا بدك تعلن عنو\n",
      "\n",
      "\n",
      "SAL\tDAM\t بتعرف بجغرافيه اليابان\n",
      "\n",
      "\n",
      "DAM\tJER\t بدك اللفافات الاصغر ولا الاكبر\n",
      "\n",
      "\n",
      "AMM\tSAL\t جاج مشوي لو سمحت\n",
      "\n",
      "\n",
      "JER\tAMM\t انا باخد واحد نقانق وكولا\n",
      "\n",
      "\n",
      "TRI\tDAM\t من وين نشردي مفرش طاوله\n",
      "\n",
      "\n",
      "BEI\tDAM\t طالعلي طفح عايديي\n",
      "\n",
      "\n",
      "ALX\tDAM\t نبيت تاني لو سمحت\n",
      "\n",
      "\n",
      "SAN\tJER\t القطار بيوقف في بريغتون\n",
      "\n",
      "\n",
      "BEN\tJER\t خمسين جنيه\n",
      "\n",
      "\n",
      "SAN\tJER\t جلد التمساح\n",
      "\n",
      "\n",
      "BEI\tALE\t عفوا بجي بعدين\n",
      "\n",
      "\n",
      "RIY\tAMM\t عندي معداتي الخاصه\n",
      "\n",
      "\n",
      "AMM\tSAL\t شو هاي الموسيقي\n",
      "\n",
      "\n",
      "SAN\tALE\t عنشارك\n",
      "\n",
      "\n",
      "JER\tAMM\t كمان كم دقيقه لو سمحت\n",
      "\n",
      "\n",
      "SAL\tDAM\t هي الرقم\n",
      "\n",
      "\n",
      "ALX\tDAM\t انا طلبته من وقت طويل\n",
      "\n",
      "\n",
      "CAI\tBEI\t عندي اختين\n",
      "\n",
      "\n",
      "SAL\tAMM\t مخطط اضل اطنعشر يوم\n",
      "\n",
      "\n",
      "AMM\tDAM\t عبي نموذج التسجيل هاد لو سمحت\n",
      "\n",
      "\n",
      "BEI\tSAL\t ما في و لا اي واحد\n",
      "\n",
      "\n",
      "JER\tSAL\t بتستقبلني الليله\n",
      "\n",
      "\n",
      "DAM\tBEI\t انو اسرع التاكسي ولا سياره الاسعاف\n",
      "\n",
      "\n",
      "JED\tALE\t السياره تطلع اصوات غريبه\n",
      "\n",
      "\n",
      "AMM\tALE\t هي بطاقه الهويه تبعتي\n",
      "\n",
      "\n",
      "AMM\tJER\t بتقدر تخصمها اكتر لعشرين دولار لو سمحت\n",
      "\n",
      "\n",
      "SAL\tJER\t انزل هون و انقل علي الباص رقم سته\n",
      "\n",
      "\n",
      "BEI\tDAM\t وين فيني صف سيارتي\n",
      "\n",
      "\n",
      "CAI\tDAM\t انا طلبته من وقت طويل\n",
      "\n",
      "\n",
      "SAL\tJER\t بتقدر تنظفلي الطاوله لو سمحت\n",
      "\n",
      "\n",
      "BEI\tJER\t مسجل الفيديو انسرق من غرفتي\n",
      "\n",
      "\n",
      "DOH\tDAM\t طلبته من زمان\n",
      "\n",
      "\n",
      "DAM\tBEI\t في محطه بنزين بعد شارعين من هون\n",
      "\n",
      "\n",
      "JER\tALE\t بدك رولات صغار ولا كبار\n",
      "\n",
      "\n",
      "SAL\tAMM\t لا بتحب تبلغ عنه\n",
      "\n",
      "\n",
      "JER\tALE\t بدي كرسي منيح\n",
      "\n",
      "\n",
      "JER\tAMM\t لا هدول كتير ثابتين\n",
      "\n",
      "\n",
      "JER\tDAM\t في جرحي\n",
      "\n",
      "\n",
      "AMM\tJER\t في ناس انصابوا\n",
      "\n",
      "\n",
      "FES\tJER\t جلد التمساح\n",
      "\n",
      "\n",
      "JER\tDAM\t طيب هلا خلينا نشوفك\n",
      "\n",
      "\n",
      "DAM\tAMM\t بوافقك الراي هوه من الاماكن المفضله عندي\n",
      "\n",
      "\n",
      "AMM\tDAM\t بدي شويه كريم للايد\n",
      "\n",
      "\n",
      "BAG\tAMM\t وين مكان حلو للسياحه\n",
      "\n",
      "\n",
      "ALE\tJER\t صرلي سخنان من الليله الماضيه\n",
      "\n",
      "\n",
      "DAM\tJER\t شو رقم الكاشير\n",
      "\n",
      "\n",
      "SAL\tDAM\t هدول المكونات طبيعيه\n",
      "\n",
      "\n",
      "ALX\tSAL\t دقايق كمان لو سمحت\n",
      "\n",
      "\n",
      "JED\tBEI\t عندي اختين\n",
      "\n",
      "\n",
      "SAL\tJER\t اسمي كيمارو بدي الغي الحجز ليوم الجمعه\n",
      "\n",
      "\n",
      "ALE\tDAM\t بتشاركني القهوه\n",
      "\n",
      "\n",
      "JER\tAMM\t القطارات وقفت عشان الاضراب\n",
      "\n",
      "\n",
      "BEI\tALE\t ما في ولا تكلفه ضروريه\n",
      "\n",
      "\n",
      "BAG\tAMM\t اسف راح ارجع بعدن\n",
      "\n",
      "\n",
      "AMM\tJER\t ملح لو سمحت\n",
      "\n",
      "\n",
      "DAM\tSAL\t رح نشارك\n",
      "\n",
      "\n",
      "ALE\tBEI\t عندي اختين\n",
      "\n",
      "\n",
      "ALE\tJER\t بدي لمبديره\n",
      "\n",
      "\n",
      "DOH\tBEI\t نسيت مشروباتنا\n",
      "\n",
      "\n",
      "DAM\tAMM\t في شي ممكن اخده لعلاج هاد الطفح\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALX\tDAM\t فنجان قهوه لو سمحت\n",
      "\n",
      "\n",
      "ALX\tAMM\t اطلع من الباب اللي هناك واستني في محطه رقم سته\n",
      "\n",
      "\n",
      "SAL\tJER\t مش عارف قديش اترك بقشيش\n",
      "\n",
      "\n",
      "MUS\tBEI\t عندك واحد غير\n",
      "\n",
      "\n",
      "JER\tAMM\t احنا هون ليوم\n",
      "\n",
      "\n",
      "TRI\tDAM\t عندك منه الوان تانيه\n",
      "\n",
      "\n",
      "SAL\tAMM\t اطلع من هاد الباب هناك و استني عند نقطه التوقف سته\n",
      "\n",
      "\n",
      "ALE\tSAL\t الشارع كان معجء بالسيارات\n",
      "\n",
      "\n",
      "SAL\tJER\t شو الاسرع تكسي و لاسياره اسعاف\n",
      "\n",
      "\n",
      "DAM\tAMM\t لو سمحت بدي استخدم الحمام\n",
      "\n",
      "\n",
      "SFX\tSAL\t ما عندي لا انديه و لا احذيه\n",
      "\n",
      "\n",
      "KHA\tAMM\t رحله رقم اتنين صفر تمنيه الي طوكيو\n",
      "\n",
      "\n",
      "ASW\tALE\t كم ولايه جنب طوكيو\n",
      "\n",
      "\n",
      "JER\tAMM\t ما بقدر ازبط الصوره\n",
      "\n",
      "\n",
      "SAN\tSAL\t لو سمحت غلفهن منفصلات\n",
      "\n",
      "\n",
      "DAM\tALE\t بتفضل طاوله بالمطعم الرءيسي ولا بغرفه خاصه استاذ\n",
      "\n",
      "\n",
      "BEI\tALE\t كل هالمكونات طبيعيه\n",
      "\n",
      "\n",
      "DAM\tBEI\t ما بعرف اديش لازم اترك بخشيش\n",
      "\n",
      "\n",
      "SAL\tBEI\t خلينا نحضر تلفزيون في لعبه بايسبول شغاله\n",
      "\n",
      "\n",
      "JER\tALE\t تلاتميه وخمسين دولار هدا اكتر من ميزانيتي\n",
      "\n",
      "\n",
      "RIY\tDAM\t طلبته من وقت طويل\n",
      "\n",
      "\n",
      "JED\tJER\t الشارع كان مليان سيارات\n",
      "\n",
      "\n",
      "JER\tAMM\t انا بدي كاسه نبيد\n",
      "\n",
      "\n",
      "MUS\tAMM\t انا رايح بقعد مع صديق\n",
      "\n",
      "\n",
      "DAM\tALE\t هي هويتي\n",
      "\n",
      "\n",
      "SAL\tAMM\t القطارات وقفت عشان الاضراب\n",
      "\n",
      "\n",
      "DAM\tAMM\t هاد الكرت تمام\n",
      "\n",
      "\n",
      "SAL\tDAM\t المحل هاد يفتح بكرا\n",
      "\n",
      "\n",
      "JER\tALE\t عفوا بدي استعمل الحمام\n",
      "\n",
      "\n",
      "SAN\tJER\t خمسين جنيه\n",
      "\n",
      "\n",
      "KHA\tAMM\t بتقدر توصل شنطتي للغرفه\n",
      "\n",
      "\n",
      "BEI\tALE\t النتيجه طابه ضربتين\n",
      "\n",
      "\n",
      "JER\tDAM\t هي الرقم\n",
      "\n",
      "\n",
      "JER\tBEI\t عندي اختين\n",
      "\n",
      "\n",
      "AMM\tDAM\t ورجيني واحد اعرض\n",
      "\n",
      "\n",
      "BAG\tAMM\t ممكن تبدلي هاي القرط بشي بقراصات\n",
      "\n",
      "\n",
      "FES\tAMM\t ممكن تستضفني هاد الليه\n",
      "\n",
      "\n",
      "AMM\tBEI\t عندي اختين\n",
      "\n",
      "\n",
      "MUS\tSAL\t هاي بطاقتي الشخصيه\n",
      "\n",
      "\n",
      "JED\tAMM\t نبيذ تاني لو سمحت\n",
      "\n",
      "\n",
      "JED\tALE\t تلاتميه وخمسين دولار فوق ميزانيتي\n",
      "\n",
      "\n",
      "AMM\tSAL\t من وين بقدر اشتري غطا طاوله\n",
      "\n",
      "\n",
      "BAS\tBEI\t بالعاده لازم تتاخر بالشغل\n",
      "\n",
      "\n",
      "JER\tALE\t وانا كمان\n",
      "\n",
      "\n",
      "ALX\tALE\t وانا كمان\n",
      "\n",
      "\n",
      "AMM\tJER\t ما في منهم\n",
      "\n",
      "\n",
      "JER\tAMM\t بدي امدد قعدتي هون كمان يومين\n",
      "\n",
      "\n",
      "SAL\tJER\t بتقدر تشرح بطريقه او باخري عن مرضك بالانجليزي\n",
      "\n",
      "\n",
      "JED\tAMM\t عندك وحده تانيه\n",
      "\n",
      "\n",
      "SAL\tJER\t بتقدر تضل ببيتي\n",
      "\n",
      "\n",
      "DOH\tALE\t عندك واحد اكبر\n",
      "\n",
      "\n",
      "JER\tSAL\t هيك تمام وين بنقدر نستناك\n",
      "\n",
      "\n",
      "AMM\tJER\t خمسين جنيه\n",
      "\n",
      "\n",
      "ALE\tBEI\t اسمي كيمورا بدي الغي حجزي يوم الجمعه\n",
      "\n",
      "\n",
      "DAM\tJER\t هيك منيح وين نستناك\n",
      "\n",
      "\n",
      "ALE\tDAM\t بوقف القطار ببرايتون\n",
      "\n",
      "\n",
      "JER\tBEI\t فرجيني واحد اعرض\n",
      "\n",
      "\n",
      "AMM\tDAM\t ما في مشكله\n",
      "\n",
      "\n",
      "RIY\tAMM\t دله قهوه لو سمحت\n",
      "\n",
      "\n",
      "BAG\tSAL\t عندك وحده اكبر\n",
      "\n",
      "\n",
      "TRI\tJER\t خمسين جنيه\n",
      "\n",
      "\n",
      "BEI\tJER\t وين في محل منيح للسياحه\n",
      "\n",
      "\n",
      "JER\tDAM\t معي عدتي\n",
      "\n",
      "\n",
      "DAM\tBEI\t معطله فيك تفحصلي كمرتي\n",
      "\n",
      "\n",
      "BEI\tAMM\t بدي اعمل حجز عرحله خطوط النورثويست رقم زيرو سته ل خمسه الشهر\n",
      "\n",
      "\n",
      "SAL\tDAM\t بتحب تنضملي لقهوه\n",
      "\n",
      "\n",
      "DAM\tJER\t انسرق مسجل الفيديو من غرفتي\n",
      "\n",
      "\n",
      "DAM\tBEI\t اكيد بدك كيرلي\n",
      "\n",
      "\n",
      "ALE\tBEI\t فرجيني واحد اعرض\n",
      "\n",
      "\n",
      "BAS\tJER\t خمسين جنيه\n",
      "\n",
      "\n",
      "TRI\tJER\t ملح لو سمحت\n",
      "\n",
      "\n",
      "DAM\tJER\t خمسين جنيه\n",
      "\n",
      "\n",
      "BEN\tSAL\t عندك وحده اكبر\n",
      "\n",
      "\n",
      "JED\tDAM\t طلبته من زمان\n",
      "\n",
      "\n",
      "KHA\tAMM\t خلينا نشاهد التلفزيون في لعبه بيسبول شغاله\n",
      "\n",
      "\n",
      "DAM\tBEI\t انسيت مشروباتنا\n",
      "\n",
      "\n",
      "AMM\tSAL\t بتقدر باي طريقه تشرح عن مرضك بالانجليزي\n",
      "\n",
      "\n",
      "AMM\tDAM\t اكيد بدك اياه كيرلي\n",
      "\n",
      "\n",
      "DAM\tAMM\t بدي كاسه مي لاخد دوا لو سمحت\n",
      "\n",
      "\n",
      "DAM\tBEI\t رح اخد هوت دوغ و كولا\n",
      "\n",
      "\n",
      "RIY\tALE\t بدون اي رسم اضافيه\n",
      "\n",
      "\n",
      "BAG\tJER\t خمسين جنيه\n",
      "\n",
      "\n",
      "BEI\tALE\t مي الدوا تبعي\n",
      "\n",
      "\n",
      "ALE\tDAM\t رح نكون هون لمده يوم\n",
      "\n",
      "\n",
      "JER\tBEI\t تلاتين دولار و تمانين\n",
      "\n",
      "\n",
      "DAM\tBEI\t بدي اطلب اذا بتريد\n",
      "\n",
      "\n",
      "AMM\tBEI\t عندك اي اشي بحوالي تمانين دولار بالظبط\n",
      "\n",
      "\n",
      "JER\tAMM\t لو سمحت لف كل واحد لحاله\n",
      "\n",
      "\n",
      "RIY\tBEI\t نسيت مشروباتنا\n",
      "\n",
      "\n",
      "SAL\tJER\t في ناس مصابين\n",
      "\n",
      "\n",
      "DOH\tJER\t خمسين جنيه\n",
      "\n",
      "\n",
      "DAM\tSAL\t اديش متوسط رسوم الفاكس الدوليه تبعك كل شهر\n",
      "\n",
      "\n",
      "DAM\tBEI\t فيك تحجز مناسبات\n",
      "\n",
      "\n",
      "DOH\tALE\t مافي\n",
      "\n",
      "\n",
      "AMM\tALE\t تلاتين دولار وتمانين سنت\n",
      "\n",
      "\n",
      "ALE\tBEI\t ما في طاول\n",
      "\n",
      "\n",
      "JER\tBEI\t بدي كريم لليل\n",
      "\n",
      "\n",
      "AMM\tALE\t انت بتعرف عن جغرافيه اليابان\n",
      "\n",
      "\n",
      "KHA\tALE\t املاح الحمام العشبي بتخلي بشرتك تحس ناعمه و ملساء\n",
      "\n",
      "\n",
      "RIY\tBEI\t عندي اختين\n",
      "\n",
      "\n",
      "DAM\tALE\t عندك واحد اكبر\n",
      "\n",
      "\n",
      "SAL\tJER\t شو الاجره لمانشستر\n",
      "\n",
      "\n",
      "DAM\tALE\t ما طلع شي من المكنه\n",
      "\n",
      "\n",
      "JER\tALE\t بدي خريطه سان فرانسيسكو و المنطقه حواليها\n",
      "\n",
      "\n",
      "TUN\tALE\t ما خرج شء مالماكينه\n",
      "\n",
      "\n",
      "TRI\tJER\t في ناس انصابو\n",
      "\n",
      "\n",
      "SAL\tALE\t رح لفندقك حوالي الساعه تسعه المسا\n",
      "\n",
      "\n",
      "AMM\tBEI\t في كازيه علي بعد شارعين من هون\n",
      "\n",
      "\n",
      "TUN\tAMM\t عنا بيرا وسكي براندي جين فدكا و شراب\n",
      "\n",
      "\n",
      "TRI\tJER\t في عندي طفح علي يدي\n",
      "\n",
      "\n",
      "ALE\tAMM\t بدي مقعد كويس\n",
      "\n",
      "\n",
      "JED\tAMM\t براد قهوه لو سمحت\n",
      "\n",
      "\n",
      "AMM\tALE\t السياره بتطلع صوت غريب\n",
      "\n",
      "\n",
      "DOH\tSAL\t لو سمحت لا تعطي احد غيري هالمفتاح\n",
      "\n",
      "\n",
      "DAM\tAMM\t بدي اياك تاخدني علي اماكن مميزه انا ساءح متل ما بتعرف\n",
      "\n",
      "\n",
      "SAL\tAMM\t شو هاد لو سمحت\n",
      "\n",
      "\n",
      "SAL\tALE\t رح اخد كاسه نبيذ\n",
      "\n",
      "\n",
      "KHA\tSAL\t نمت خلال منبه السته و نص\n",
      "\n",
      "\n",
      "SAL\tJER\t غالي صح\n",
      "\n",
      "\n",
      "ALG\tJER\t في جلد التمساح\n",
      "\n",
      "\n",
      "AMM\tJER\t لازم الحق طياره الساعه عشره الصبح\n",
      "\n",
      "\n",
      "SAL\tDAM\t املاح حمام الاعشاب بيخلي بشرتك ناعمه و رقيقه\n",
      "\n",
      "\n",
      "SAL\tJER\t لو سمحت عبي نموذج التسجيل\n",
      "\n",
      "\n",
      "SAL\tJER\t خمسين جنيه\n",
      "\n",
      "\n",
      "SAL\tAMM\t بقدر احجز اجر سياره هون\n",
      "\n",
      "\n",
      "SAN\tJER\t مسجل الفيديو استرق من غرفتي\n",
      "\n",
      "\n",
      "CAI\tBEI\t ادي الرقم\n",
      "\n",
      "\n",
      "SAL\tAMM\t كمان كم دقيقه\n",
      "\n",
      "\n",
      "SAN\tJER\t ملح لو سمحت\n",
      "\n",
      "\n",
      "DAM\tBEI\t بفتح الاربعا الصبح او الجمعه بعد الضهر\n",
      "\n",
      "\n",
      "SAL\tJER\t شو بقدر افرجيك\n",
      "\n",
      "\n",
      "SAN\tSAL\t شكرا مرحبا شكرا لانتظارك\n",
      "\n",
      "\n",
      "JED\tSAL\t عندك وحده اكبر\n",
      "\n",
      "\n",
      "ALE\tAMM\t عندي معداتي الخاصه\n",
      "\n",
      "\n",
      "SAL\tJER\t في محطه بنزين بعد تقاطعين من هون\n",
      "\n",
      "\n",
      "BEI\tSAL\t من وين بقدر اشتري شرشف طاوله\n",
      "\n",
      "\n",
      "ALE\tBEI\t لا بتريد تبلغ عنو\n",
      "\n",
      "\n",
      "ALE\tJER\t في ناس مصابين\n",
      "\n",
      "\n",
      "SAL\tJER\t ما بفهم امريكي بحكي انجليزي بريطاني\n",
      "\n",
      "\n",
      "AMM\tSAL\t وين بقدر اروح اشوف اطلاله جد كتير حلوه\n",
      "\n",
      "\n",
      "BEI\tAMM\t بدي جاكيت رياضه\n",
      "\n",
      "\n",
      "BEN\tAMM\t الشارع كان معبي سيارات\n",
      "\n",
      "\n",
      "DOH\tALE\t في شي ممكن استخدمه حق هالحبوب\n",
      "\n",
      "\n",
      "DAM\tBEI\t انا ايكيدا عندي حجز طاوله عالساعه سته و نص المسا بس بدي اعتذر رح اتاخر نص ساعه\n",
      "\n",
      "\n",
      "AMM\tDAM\t عفوا وين في محطه قريبه من هون\n",
      "\n",
      "\n",
      "SAL\tJER\t بدي اطلب لو سمحت\n",
      "\n",
      "\n",
      "BEN\tJER\t مسجل الفيديو انسرق من داري\n",
      "\n",
      "\n",
      "DAM\tAMM\t لازم سافر برحله الساعه عشره الصبح\n",
      "\n",
      "\n",
      "BEI\tALE\t بوصل عالاوتيل لعندك حوالي التسعه المسا\n",
      "\n",
      "\n",
      "SAL\tAMM\t احنا هون ليوم\n",
      "\n",
      "\n",
      "TUN\tJER\t اعطيني امبوبه\n",
      "\n",
      "\n",
      "AMM\tJER\t وين في مكان منيح للسياحه\n",
      "\n",
      "\n",
      "JER\tDAM\t معي تلات شناتي\n",
      "\n",
      "\n",
      "JED\tAMM\t النتيجه ضربه وحده واتنين برا\n",
      "\n",
      "\n",
      "KHA\tJER\t خمسين جنيه\n",
      "\n",
      "\n",
      "CAI\tALE\t القطورات وقفت بسبب الاضراب\n",
      "\n",
      "\n",
      "ALE\tJER\t خمسين جنيه\n",
      "\n",
      "\n",
      "DAM\tBEI\t عندك شي بتمانين دولار بالظبط\n",
      "\n",
      "\n",
      "TUN\tJER\t خمسين جنيه\n",
      "\n",
      "\n",
      "BAS\tBEI\t نسيت مشروباتنه\n",
      "\n",
      "\n",
      "BAS\tALE\t هاي بطاقه هويتي\n",
      "\n",
      "\n",
      "AMM\tALE\t عنا حوالي تلاتين نوع من زيوت الحمام\n",
      "\n",
      "\n",
      "BEI\tALE\t هالبطاقه تمام\n",
      "\n",
      "\n",
      "SAN\tBEI\t بيجي مع سلطه و اختيارك من بطاط مشوي او شبس\n",
      "\n",
      "\n",
      "BEI\tALE\t معك واحد تاني\n",
      "\n",
      "\n",
      "SFX\tBEI\t نتشاركوا\n",
      "\n",
      "\n",
      "DAM\tALE\t بدي خريطه سان فرانسيسو والمنطقه المحيطه\n",
      "\n",
      "\n",
      "BEI\tALE\t تلاتين دولار وتمانين سنت\n",
      "\n",
      "\n",
      "DOH\tAMM\t في اي جهه من يونيون سكوير هو\n",
      "\n",
      "\n",
      "AMM\tJER\t بدي لمبه\n",
      "\n",
      "\n",
      "ALE\tBEI\t في محطه بنزين بعد شارعين من هون\n",
      "\n",
      "\n",
      "MSA\tSAL\t شكرا مرحبا شكرا لانتظارك\n",
      "\n",
      "\n",
      "SAN\tSAL\t بين اخطط اتعلم غولف\n",
      "\n",
      "\n",
      "RAB\tJER\t خمسين جنيه\n",
      "\n",
      "\n",
      "CAI\tJER\t لازم الحق طياره عشره الصبح\n",
      "\n",
      "\n",
      "BEN\tAMM\t بقرج قهوه لو سمحت\n",
      "\n",
      "\n",
      "JER\tALE\t رح يكون في انتظار عشر دقايق او اكتر\n",
      "\n",
      "\n",
      "KHA\tAMM\t ما ضروري الشحن\n",
      "\n",
      "\n",
      "DOH\tBEI\t بنتشارك\n",
      "\n",
      "\n",
      "DAM\tJER\t بدي لمبه\n",
      "\n",
      "\n",
      "JED\tAMM\t الحمام ما يسحب السيفون\n",
      "\n",
      "\n",
      "SAL\tBEI\t ما في\n",
      "\n",
      "\n",
      "SAL\tJER\t وين بقدر اصف سيارتي\n",
      "\n",
      "\n",
      "SAL\tJER\t رح اضل مع صاحبي\n",
      "\n",
      "\n",
      "SAL\tAMM\t بكرج قهوه لو سمحت\n",
      "\n",
      "\n",
      "BAS\tAMM\t هاي رحله علي طول اليوم\n",
      "\n",
      "\n",
      "DAM\tAMM\t هاد القطار بوقف بليك فورست صح\n",
      "\n",
      "\n",
      "SAL\tAMM\t شو متوسط ​رسوم الفاكس الدوليه تبعتك كل شهر\n",
      "\n",
      "\n",
      "DAM\tAMM\t كم دقيقه تانيه لو سمحت\n",
      "\n",
      "\n",
      "ALX\tBEI\t في ناس اتصابت\n",
      "\n",
      "\n",
      "BEI\tDAM\t صرلي من مبارح بالليل محرور\n",
      "\n",
      "\n",
      "ALE\tJER\t وين في محل منيح للسياحه\n",
      "\n",
      "\n",
      "SAL\tJER\t بدك لفات اصغر و لا اكبر\n",
      "\n",
      "\n",
      "JER\tSAL\t بتقدر تنزل السعر لعشرين دولار لو سمحت\n",
      "\n",
      "\n",
      "DAM\tALE\t بدي مدد اقامني هون يومين\n",
      "\n",
      "\n",
      "SAL\tJER\t لازم الحق طياره العشره الصبح\n",
      "\n",
      "\n",
      "BAS\tAMM\t انا طلبته من زمان\n",
      "\n",
      "\n",
      "ALX\tJER\t ملح لو سمحت\n",
      "\n",
      "\n",
      "DAM\tJER\t صرلي صخنان من الليله الماضيه\n",
      "\n",
      "\n",
      "SAL\tJER\t انا مش شاطر بالانجليزي في اي حدا هون بيحكي ياباني\n",
      "\n",
      "\n",
      "SAL\tJER\t ابصر اذا في طاوله فاضيه جنب الشباك علي الساعه سبعه\n",
      "\n",
      "\n",
      "SAL\tJER\t الصعود ببلش علي الاربعه و نص عشان هيك كون هناك قبل\n",
      "\n",
      "\n",
      "SAL\tJER\t ايكيدا بيحكي معك عندي حجز لطاوله اليوم علي الساعه سته و نص بس للاسف رح اوصل متاخر نص ساعه\n",
      "\n",
      "\n",
      "ALX\tALE\t عندك واحد اكبر\n",
      "\n",
      "\n",
      "AMM\tJER\t بقدر ادعيك علي الغدا برا ليوم\n",
      "\n",
      "\n",
      "JER\tAMM\t بدي ورق ملاحظات\n",
      "\n",
      "\n",
      "JER\tDAM\t بقرد اعزمك علي العشا شي مره\n",
      "\n",
      "\n",
      "DAM\tBEI\t بعتذر برجع بعدين\n",
      "\n",
      "\n",
      "SAL\tJER\t بتقدر تحجز انشطه\n",
      "\n",
      "\n",
      "SAL\tJER\t وين في مكان منيح للسياحه\n",
      "\n",
      "\n",
      "JER\tAMM\t ابريق قهوه لو سمحت\n",
      "\n",
      "\n",
      "RIY\tJER\t مسجل الفيديو هذا انسرق من غرفتي\n",
      "\n",
      "\n",
      "TRI\tALE\t حانتشاركو\n",
      "\n",
      "\n",
      "SAL\tALE\t السياره بتطلع صوت غريب\n",
      "\n",
      "\n",
      "SAL\tBEI\t اكيد بدك كيرلي\n",
      "\n",
      "\n",
      "JER\tAMM\t اوه في كتير اشياء لازم تشوفها في قريه جرينويش\n",
      "\n",
      "\n",
      "BEI\tALE\t بدي خريطه لسان فرانسيسكو و المنطقه المحيطه\n",
      "\n",
      "\n",
      "DOH\tJER\t ملح لو سمحت\n",
      "\n",
      "\n",
      "SAL\tJER\t بالعاده بتشتغل لوقت متاخر\n",
      "\n",
      "\n",
      "KHA\tBEI\t نسيت مشروباتنا\n",
      "\n",
      "\n",
      "SAL\tJER\t مسجل الفيديو انسرق من غرفتي\n",
      "\n",
      "\n",
      "DAM\tALE\t حاس بضيق بالصدر\n",
      "\n",
      "\n",
      "JER\tDAM\t تشرب معي قهوه\n",
      "\n",
      "\n",
      "BEI\tDAM\t يمكن بس لازم نوزنن مفصولين\n",
      "\n",
      "\n",
      "ALE\tSAL\t وين بقدر اروح اشوف منظر حلو متل العاده\n",
      "\n",
      "\n",
      "BEI\tALE\t ما بفهم اميركي بحكي اللغه الانكليزي تبع بريطانيا\n",
      "\n",
      "\n",
      "AMM\tDAM\t بدي مقعد منيح\n",
      "\n",
      "\n",
      "ALE\tBEI\t عندك غيرو\n",
      "\n",
      "\n",
      "ALE\tDAM\t شكرا الك مرحبا شكرا عالانتظار\n",
      "\n",
      "\n",
      "BEI\tDAM\t فيني انزل عندك الليله\n",
      "\n",
      "\n",
      "DAM\tAMM\t شو هاد لو سمحت\n",
      "\n",
      "\n",
      "JER\tAMM\t ممكن تتصلو تفيقوني بكرا الساعه خمسه و نص الصبح\n",
      "\n",
      "\n",
      "MUS\tDAM\t ماشي مشكله\n",
      "\n",
      "\n",
      "DOH\tAMM\t وين مكان حلو للسياحه\n",
      "\n",
      "\n",
      "MUS\tSAL\t لا هي داءم\n",
      "\n",
      "\n",
      "DAM\tALE\t السياره عم بطلع صوت غريب\n",
      "\n",
      "\n",
      "SAL\tJER\t بدي كريم ليلي\n",
      "\n",
      "\n",
      "SAL\tJER\t بتقدر تفرجيني شويه فساتين\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAL\tJER\t الشارع كان مليان سيارات\n",
      "\n",
      "\n",
      "BAG\tAMM\t عندي معداتي الخاصه\n",
      "\n",
      "\n",
      "SAN\tDAM\t معي علاجي\n",
      "\n",
      "\n",
      "SAL\tDAM\t في طفع جلدي علي ايدي\n",
      "\n",
      "\n",
      "SAL\tBEI\t ما بقدر انام منيح بالليل\n",
      "\n",
      "\n",
      "DAM\tJER\t ملح لو سمحت\n",
      "\n",
      "\n",
      "MUS\tJER\t ملح لو سمحت\n",
      "\n",
      "\n",
      "JER\tALE\t هدول مكونات طبيعيه\n",
      "\n",
      "\n",
      "KHA\tJER\t مسجل الفيديو اتسرق من غرفتي\n",
      "\n",
      "\n",
      "BEI\tAMM\t اسمي كيمورا بدي الغي حجزي الجمعه\n",
      "\n",
      "\n",
      "DAM\tAMM\t ممكن تشرب معي قهوه\n",
      "\n",
      "\n",
      "SAL\tJER\t شكلو منيح وين بنقدر نستناك\n",
      "\n",
      "\n",
      "BEI\tJER\t في ناس انجرحو\n",
      "\n",
      "\n",
      "JER\tAMM\t شو اصغر عمر عشان نعمله\n",
      "\n",
      "\n",
      "ALE\tSAL\t لا بدي استاجر نص مجموعه مضارب وحذاء\n",
      "\n",
      "\n",
      "SAL\tBEI\t نسيت مشروباتنا\n",
      "\n",
      "\n",
      "MOS\tBEI\t السياره عتطلع اصوات غريبي\n",
      "\n",
      "\n",
      "MUS\tBEI\t عندي اختين\n",
      "\n",
      "\n",
      "BAG\tJER\t مسجل الفيديو انباك من غرفتي\n",
      "\n",
      "\n",
      "DAM\tSAL\t هاد بيجي مع بوفيه السلطه بالاضافه لتشكيله بطاطا مشويه او مقليه\n",
      "\n",
      "\n",
      "AMM\tJER\t وين بقدر اصف سيارتي\n",
      "\n",
      "\n",
      "BAS\tAMM\t انا اسف راح ارجع بعدين\n",
      "\n",
      "\n",
      "SAL\tAMM\t لو سمحت بدي استخدم الحمام\n",
      "\n",
      "\n",
      "ALX\tJER\t خمسين جنيه\n",
      "\n",
      "\n",
      "BEN\tSAL\t من عشره لعشرين لو سمحت\n",
      "\n",
      "\n",
      "DAM\tALE\t هدول مكونات طبيعيه\n",
      "\n",
      "\n",
      "ALE\tJER\t بتقدر تعيف غراضي للساعه تلاته\n",
      "\n",
      "\n",
      "BEI\tDAM\t طيب هلا خلينا نشوفك\n",
      "\n",
      "\n",
      "BEI\tJER\t خمسين جنيه\n",
      "\n",
      "\n",
      "KHA\tALE\t ما مشكله\n",
      "\n",
      "\n",
      "ASW\tALE\t وانا كمان\n",
      "\n",
      "\n",
      "SFX\tJER\t خمسين جنيه\n",
      "\n",
      "\n",
      "JER\tSAL\t بقدر ادفع بشيك سياحي\n",
      "\n",
      "\n",
      "ALX\tBEI\t هي اوضتك بتطل علي المدينه\n",
      "\n",
      "\n",
      "RAB\tJER\t من جلد التمساح\n",
      "\n",
      "\n",
      "RIY\tSAL\t بتخليني اسكن عندك الليله\n",
      "\n",
      "\n",
      "AMM\tALE\t هدول مكونات طبيعيه\n",
      "\n",
      "\n",
      "JER\tSAL\t جاج مشوي لو سمحت\n",
      "\n",
      "\n",
      "SAL\tJER\t ملح لو سمحت\n",
      "\n",
      "\n",
      "MOS\tAMM\t ممكن بس لازم نوزنم منفصلين\n",
      "\n",
      "\n",
      "DAM\tAMM\t ممكن احجز غرفه مزدوجه بتطل عالمحيط\n",
      "\n",
      "\n",
      "MUS\tDAM\t شو هالموسيقي\n",
      "\n",
      "\n",
      "SAL\tAMM\t بدي ورق ملاحظات\n",
      "\n",
      "\n",
      "BEN\tBEI\t عندي اختين\n",
      "\n",
      "\n",
      "JED\tJER\t خمسين جنيه\n",
      "\n",
      "\n",
      "AMM\tDAM\t ممكن تتصل في الصبح بكير لو سمحت\n",
      "\n",
      "\n",
      "JED\tAMM\t انا رايح اقعد مع صاحبي\n",
      "\n",
      "\n",
      "AMM\tJER\t بتقدر تسجل الاحداث\n",
      "\n",
      "\n",
      "ALE\tBEI\t يمكن بس لازم نوزنون لحال\n",
      "\n",
      "\n",
      "BEI\tALE\t عم خطط تءبءا طنعشر يوم\n",
      "\n",
      "\n",
      "DAM\tSAL\t جاج مشوي لو سمحت\n",
      "\n",
      "\n",
      "ALE\tJER\t بقدر ادفع بشيكات سياحيه\n",
      "\n",
      "\n",
      "BEI\tAMM\t في طاوله متوفره حد الشباك لسبع اشخاص الليله\n",
      "\n",
      "\n",
      "DAM\tALE\t بدي شريط اله كاتبه\n",
      "\n",
      "\n",
      "SAL\tJER\t انا ضعت بتقدر تساعدني\n",
      "\n",
      "\n",
      "ALE\tJER\t لازم الحق طياره الساعه عشره الصبح\n",
      "\n",
      "\n",
      "DAM\tAMM\t بدي جاكيت رياضي\n",
      "\n",
      "\n",
      "SAL\tALE\t القطار وقف عند بحيره فورست صح\n",
      "\n",
      "\n",
      "TUN\tJER\t جلد التمساح\n",
      "\n",
      "\n",
      "SAL\tALE\t هي هويتي\n",
      "\n",
      "\n",
      "FES\tALE\t املاح حمام العشبيه كتخلي بشرتك ناعمه وسلسه\n",
      "\n",
      "\n",
      "AMM\tJER\t حاس حالي مقشعر ومعدتي بتوجعني كتير\n",
      "\n",
      "\n",
      "MUS\tJER\t تم سرقه مسجل الفيديو من غرفتي\n",
      "\n",
      "\n",
      "DOH\tSAL\t في شي غلط في هالبطاقه ممكن تعطيني وحده ثانيه لو سمحت\n",
      "\n",
      "\n",
      "JER\tSAL\t لا بتحب تقدم تقرير عنه\n",
      "\n",
      "\n",
      "JED\tAMM\t ما عندي مضرب ولا جزمه\n",
      "\n",
      "\n",
      "ALE\tDAM\t هي الرقم\n",
      "\n",
      "\n",
      "AMM\tALE\t بدي شريط اله كاتبه\n",
      "\n",
      "\n",
      "SAL\tJER\t ما قررت لسه بتقدر تعطيني وقت كمان\n",
      "\n",
      "\n",
      "AMM\tJER\t ما في داعي للرسوم\n",
      "\n",
      "\n",
      "BEN\tJER\t تقدر تنضفلي الطاوله لو سمحت\n",
      "\n",
      "\n",
      "ALE\tDAM\t طلاع من هداك الباب واستنا عالموقف رقم سته\n",
      "\n",
      "\n",
      "MSA\tAMM\t جلد التمساح الامريكي\n",
      "\n",
      "\n",
      "AMM\tJER\t تسجيل الفيديو انسرق من غرفتي\n",
      "\n",
      "\n",
      "JER\tSAL\t قديش رقم الكاشير\n",
      "\n",
      "\n",
      "MOS\tJER\t خمسين جنيه\n",
      "\n",
      "\n",
      "BEN\tDAM\t طلبته من زمان\n",
      "\n",
      "\n",
      "ALE\tAMM\t العدد طابه وحده ضربتين\n",
      "\n",
      "\n",
      "DOH\tALE\t املاح الحمام العشبيه بتخلي بشرتك ناعمه\n",
      "\n",
      "\n",
      "JER\tAMM\t لو سمحت اصرف شك سياحي\n",
      "\n",
      "\n",
      "CAI\tDAM\t ممكن تفرجني فساتين\n",
      "\n",
      "\n",
      "BEI\tALE\t معك عامل التلفون الدولي\n",
      "\n",
      "\n",
      "AMM\tJER\t بدي كريم ليلي\n",
      "\n",
      "\n",
      "JED\tAMM\t لو سمحت اعطيني شراب تاني\n",
      "\n",
      "\n",
      "SAL\tJER\t بتقدر تتصل علي تصحيني بكرا علي الساعه خمسه و نص الصبح\n",
      "\n",
      "\n",
      "AMM\tALE\t هاد قطار مستقيم\n",
      "\n",
      "\n",
      "DAM\tAMM\t ما بفهم امريكي انا بحكي انجليزي بريطاني\n",
      "\n",
      "\n",
      "AMM\tJER\t حاس صدري مسكر\n",
      "\n",
      "\n",
      "DOH\tJER\t انا افتح الاربعاء الصبح والجمعه الظهر\n",
      "\n",
      "\n",
      "SAL\tJER\t بدي لمبه\n",
      "\n",
      "\n",
      "AMM\tJER\t حابب اجرب نفس طبق الاكل هداك\n",
      "\n",
      "\n",
      "JER\tAMM\t عفوا وين المحطه القريبه من هون\n",
      "\n",
      "\n",
      "MUS\tJER\t عندك اكبر\n",
      "\n",
      "\n",
      "RIY\tJER\t وين اقدر اصف سيارتي\n",
      "\n",
      "\n",
      "BAG\tSAL\t عندي طفح علي ذراعي\n",
      "\n",
      "\n",
      "MOS\tBEI\t عندي اختين\n",
      "\n",
      "\n",
      "JER\tAMM\t بدي جاكيت رياضه\n",
      "\n",
      "\n",
      "DAM\tSAL\t لو سمحت وين المحطه القريبه من هون\n",
      "\n",
      "\n",
      "SAL\tDAM\t بيرح هاد الباص علي فندق هيلتون\n",
      "\n",
      "\n",
      "SAL\tAMM\t بتقدر تاكيد طلبي وهي تذكره طيران\n",
      "\n",
      "\n",
      "ALE\tBEI\t بدي جاكيت سبور\n",
      "\n",
      "\n",
      "DOH\tAMM\t بعد كم دقيقه لو سمحت\n",
      "\n",
      "\n",
      "KHA\tAMM\t عندي معداتي الخاصه\n",
      "\n",
      "\n",
      "ALE\tAMM\t ما بقدر اعدل الصوره\n",
      "\n",
      "\n",
      "CAI\tJER\t خمسين جنيه\n",
      "\n",
      "\n",
      "BEI\tALE\t هالاملاح النباتيه تبع الحمام بتنعم البشره\n",
      "\n",
      "\n",
      "ALE\tBEI\t نزيل هون وحول عالباص رقم سته\n",
      "\n",
      "\n",
      "AMM\tALE\t اسف كتير بس ما عنا كمان شو رايك بورق انجليزي\n",
      "\n",
      "\n",
      "JED\tAMM\t لو سمحت كاش حق الشيك السياحي\n",
      "\n",
      "\n",
      "SFX\tJER\t من جلد التمساح\n",
      "\n",
      "\n",
      "BAS\tJER\t مسجل الفيديو انباك من غرفتي\n",
      "\n",
      "\n",
      "JER\tSAL\t غفيت علي منبه السته و نص\n",
      "\n",
      "\n",
      "RIY\tSAL\t لو سمحت اصرف شيك المسافر\n",
      "\n",
      "\n",
      "DAM\tJER\t في عندك غرف اكبر\n",
      "\n",
      "\n",
      "RIY\tSAL\t لو سمحت غلفهم منفصله\n",
      "\n",
      "\n",
      "SAL\tALE\t بدي شريط اله كاتبه\n",
      "\n",
      "\n",
      "SAL\tBEI\t طلبت من زمان\n",
      "\n",
      "\n",
      "JER\tALE\t هو باي جهه من يونيون سكوير\n",
      "\n",
      "\n",
      "JED\tALE\t مافي شيء خرج من الجهاز\n",
      "\n",
      "\n",
      "DAM\tAMM\t ممكن تفضيلي الطاوله لو سمحت\n",
      "\n",
      "\n",
      "JER\tALE\t السياره بتطلع اصوات غريبه\n",
      "\n",
      "\n",
      "BEN\tBEI\t نسيت مشروباتنا\n",
      "\n",
      "\n",
      "JER\tSAL\t قديش بتكلف الليموزين عشان تروح علي وسط البلد\n",
      "\n",
      "\n",
      "DAM\tAMM\t بدي كم ورقه ملاحظات\n",
      "\n",
      "\n",
      "SAL\tAMM\t شو اقل عمر لعمل هاد\n",
      "\n",
      "\n",
      "JED\tJER\t ملح لو سمحت\n",
      "\n",
      "\n",
      "JED\tAMM\t عفوا انا ضايع ممكن تساعدني\n",
      "\n",
      "\n",
      "601\n"
     ]
    }
   ],
   "source": [
    "c= 0\n",
    "for target,pre,doc in zip(y_test,pred,data_test.data):\n",
    "    \"\"\"if pre == 3:\n",
    "        gold_test_file.write(data_test.target_names[target]+ '\\n')\n",
    "        pred_test_file.write('MSA\\n')\n",
    "        #sample_file.write(data_test.target_names[target]+'\\t'+data_trains[pre].target_names[pred26[0]]+ '\\t'+doc+'\\n')\n",
    "        continue\"\"\"\n",
    "    \n",
    "    X_test = union_fine[pre].transform([doc])\n",
    "    pred26 = ensembles[pre].predict(X_test)\n",
    "    \n",
    "    if pre == 0 and data_test.target_names[target] != data_trains[pre].target_names[pred26[0]]:\n",
    "        c = c+1\n",
    "        print(data_test.target_names[target]+'\\t'+data_trains[pre].target_names[pred26[0]]+ '\\t'+doc+'\\n')\n",
    "\n",
    "    gold_test_file.write(data_test.target_names[target]+ '\\n')\n",
    "    pred_test_file.write(data_trains[pre].target_names[pred26[0]]+ '\\n')\n",
    "    #sample_file.write(data_test.target_names[target]+'\\t'+data_trains[pre].target_names[pred26[0]]+ '\\t'+doc+'\\n')\n",
    "    \n",
    "print(c)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
