{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xabuka/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "import loading\n",
    "import process_aravec\n",
    "from gensim.models import Word2Vec\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from keras.layers import Input,Embedding, Conv1D,MaxPooling1D,GlobalMaxPooling1D, Dense,Dropout,LSTM,Flatten,GRU,Bidirectional,GlobalAveragePooling1D\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns             \n",
    "from keras import regularizers\n",
    "from keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 5000\n",
    "max_len = 20\n",
    "training_samples = 8000  # We will be training on 200 samples\n",
    "validation_samples = 2000  # We will be validating on 10000 samples\n",
    "# Convolution\n",
    "kernel_size = 5\n",
    "filters = 64\n",
    "pool_size = 2\n",
    "\n",
    "# LSTM\n",
    "lstm_output_size = 70\n",
    "#keras model\n",
    "epochs = 10\n",
    "batch_size=50\n",
    "\n",
    "#data directory\n",
    "#data_dir = '../data/SplitedPalSent'\n",
    "#data_dir = '../data/ASTD'\n",
    "#data_dir = '../data/labr5/clean'\n",
    "#data_dir = '../data/labr3'\n",
    "#data_dir = '../data/labr2'\n",
    "#data_dir = '../data/Shami'\n",
    "train_dir = '../data/D6_26/6dialects/splited_train/BEI'\n",
    "test_dir = '../data/D6_26/6dialects/splited_dev/BEI'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/D6_26/6dialects/splited_train/BEI/train\n",
      "Found 8797 unique tokens.\n",
      "Shape of data tensor: (9600, 20)\n",
      "Shape of label tensor: (9600,)\n",
      "9600\n",
      "[1. 0. 0. 0. 0. 0.]\n",
      "[ 66 934  94 935 642 112   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n"
     ]
    }
   ],
   "source": [
    "import loading\n",
    "input_train, y_train  = loading.load_train(train_dir,max_len,training_samples,validation_samples,max_features, Validation = False, binary = False )\n",
    "input_test, y_test = loading.load_test(test_dir,max_len,max_features,binary = False )\n",
    "print(len(input_train))\n",
    "print((y_train[10]))\n",
    "print(input_test[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 331679 word vectors.\n",
      "0.9656\n"
     ]
    }
   ],
   "source": [
    "def embedding_matrix(data_dir,max_len,max_features):\n",
    "    ara_dir = '../data/tweet_cbow_300/'\n",
    "    word_index = loading.word_index(data_dir,max_len,max_features)\n",
    "    t_model = Word2Vec.load(os.path.join(ara_dir,'tweets_cbow_300'))\n",
    "\n",
    "    print('Found %s word vectors.' % len(t_model.wv.index2word))# how many words in aravec this model\n",
    "    embeddings_index = t_model.wv\n",
    "\n",
    "    embedding_dim = embeddings_index.vector_size #300\n",
    "    embedding_matrix = np.zeros((max_features, embedding_dim))\n",
    "\n",
    "    for word, i in word_index.items():\n",
    "        word = process_aravec.clean_str(word).replace(\" \", \"_\")\n",
    "        check = False\n",
    "        if word in embeddings_index:\n",
    "            w = word\n",
    "            check = True\n",
    "        elif word[1:] in embeddings_index:\n",
    "            w= word[1:]\n",
    "            check = True\n",
    "        elif word[:-2] in embeddings_index:\n",
    "            w= word[:-2]\n",
    "            check = True\n",
    "        if check:\n",
    "            embedding_vector = embeddings_index[w]\n",
    "            if i < max_features:\n",
    "                if embedding_vector is not None:\n",
    "                    # Words not found in embedding index will be all-zeros.\n",
    "                    embedding_matrix[i] = embedding_vector\n",
    "                    #print(len(embedding_vector))\n",
    "       \n",
    "        \n",
    "    return  embedding_matrix  \n",
    "embedding_matrix = embedding_matrix(train_dir,max_len,max_features)\n",
    "nonzero_elements = np.count_nonzero(np.count_nonzero(embedding_matrix, axis=1))\n",
    "print(nonzero_elements / max_features)\n",
    "#for dialetct PAl it only covers 35% of the vocabulary\n",
    "# for MSA it covers 98%\n",
    "#ASTD . 90%\n",
    "#shami 67%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#building model CNN + LSTM\n",
    "#tried on ASTD \n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 100,weights=[embedding_matrix], trainable=True, input_length=max_len))\n",
    "model.add(LSTM(70,dropout=0.5, recurrent_dropout=0.5))#,return_sequences=True)))\n",
    "#model.add(LSTM(64,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(30))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(3,activation='sigmoid'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics =['acc'])\n",
    "#model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 100,weights=[embedding_matrix], trainable=True, input_length=max_len))\n",
    "#model.add(Flatten())\n",
    "#model.add(Conv1D(100, 10, activation='relu'))\n",
    "model.add(Conv1D(100, 10, activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Conv1D(160, 10, activation='relu'))\n",
    "#model.add(Conv1D(160, 10, activation='relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics =['acc'])\n",
    "#model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 20, 300)           3000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 20, 256)           439296    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 64)                82176     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               6500      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 3,528,578\n",
      "Trainable params: 3,528,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#LSTM  EXP 16\n",
    "model=Sequential()\n",
    "model.add(Embedding(max_features, 300,weights=[embedding_matrix], trainable=True, input_length=max_len)) \n",
    "model.add(Bidirectional(LSTM(128,dropout=0.5, recurrent_dropout=0.5,return_sequences=True)))\n",
    "model.add(LSTM(64,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6,activation='sigmoid'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics =['acc'])\n",
    "#model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 20, 300)           1500000   \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 20, 256)           439296    \n",
      "_________________________________________________________________\n",
      "bidirectional_9 (Bidirection (None, 20, 128)           164352    \n",
      "_________________________________________________________________\n",
      "model_3 (Model)              (None, 6)                 585836    \n",
      "=================================================================\n",
      "Total params: 2,689,484\n",
      "Trainable params: 2,689,484\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#CNN_19,2\n",
    "\n",
    "\n",
    "def create_convnet(max_features, vectore_d):\n",
    "    input_shape = Input(shape=(max_features, vectore_d))\n",
    "    conv = []\n",
    "    for filters in [32,64,128]:\n",
    "        for k_size in [2,3,4,5,6]:\n",
    "            tower = Conv1D(filters, k_size, activation='relu')(input_shape)\n",
    "            tower = GlobalMaxPooling1D()(tower)\n",
    "            conv.append(tower)\n",
    "    \n",
    "    merged = layers.concatenate([tower for tower in conv], axis=1)\n",
    "   \n",
    "    \n",
    "    out = Dense(10,activation='relu')(merged)\n",
    "    #out = Dropout(0.3)(out)\n",
    "    #out = Dense(30)(out)\n",
    "    out = Dense(6, activation='sigmoid')(out)\n",
    "\n",
    "    model = Model(input_shape, out)\n",
    "    #print(model.summary())\n",
    "    from keras.utils.vis_utils import plot_model\n",
    "    #plot_model(model, to_file=filepath+'.png', show_shapes=True, show_layer_names=True)\n",
    "    return model\n",
    "\n",
    "\n",
    "input_shape =(max_features, )\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 300,weights=[embedding_matrix], trainable=True, input_length=max_len)) \n",
    "model.add(Bidirectional(LSTM(128,dropout=0.5, recurrent_dropout=0.5,return_sequences= True)))\n",
    "model.add(Bidirectional(LSTM(64,dropout=0.5, recurrent_dropout=0.5,return_sequences= True)))\n",
    "model.add(create_convnet(max_len, 128))\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics =['acc'])\n",
    "#model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#EXP LSTM 9+17\n",
    "model=Sequential()\n",
    "model.add(Embedding(max_features, 300,weights=[embedding_matrix], trainable=True, input_length=max_len)) \n",
    "model.add(Bidirectional(LSTM(128,dropout=0.5, recurrent_dropout=0.5,return_sequences=True)))\n",
    "model.add(LSTM(64,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#building model CNN + LSTM kagg\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 300,weights=[embedding_matrix], trainable=True, input_length=max_len)) \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(filters, kernel_size, padding='valid', activation='relu', strides=1))\n",
    "model.add(MaxPooling1D(pool_size=pool_size))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(32, 3, padding='valid', activation='relu', strides=1))\n",
    "#model.add(Flatten())\n",
    "model.add(LSTM(lstm_output_size, dropout = 0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(3,activation='sigmoid'))\n",
    "#model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics =['acc'])\n",
    "print(model.summary())   \n",
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='weights/kaggle.png', show_shapes=True, show_layer_names=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7680 samples, validate on 1920 samples\n",
      "Epoch 1/100\n",
      "7680/7680 [==============================] - 45s 6ms/step - loss: 1.0359 - acc: 0.5382 - val_loss: 1.5343 - val_acc: 0.3974\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.53432, saving model to weights.best.exp_OOV.hdf5\n",
      "Epoch 2/100\n",
      "7680/7680 [==============================] - 44s 6ms/step - loss: 1.0120 - acc: 0.5518 - val_loss: 1.5233 - val_acc: 0.4052\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.53432 to 1.52330, saving model to weights.best.exp_OOV.hdf5\n",
      "Epoch 3/100\n",
      "7680/7680 [==============================] - 44s 6ms/step - loss: 0.9629 - acc: 0.5651 - val_loss: 1.6471 - val_acc: 0.4151\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.52330\n",
      "Epoch 4/100\n",
      "7680/7680 [==============================] - 44s 6ms/step - loss: 0.9483 - acc: 0.5723 - val_loss: 1.6389 - val_acc: 0.4188\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.52330\n",
      "Epoch 5/100\n",
      "7680/7680 [==============================] - 45s 6ms/step - loss: 0.9227 - acc: 0.5849 - val_loss: 1.6482 - val_acc: 0.4229\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.52330\n",
      "Epoch 6/100\n",
      "7680/7680 [==============================] - 44s 6ms/step - loss: 0.8958 - acc: 0.5952 - val_loss: 1.8379 - val_acc: 0.4224\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.52330\n",
      "Epoch 7/100\n",
      "7680/7680 [==============================] - 47s 6ms/step - loss: 0.8833 - acc: 0.5962 - val_loss: 1.7616 - val_acc: 0.4245\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.52330\n",
      "Epoch 8/100\n",
      "7680/7680 [==============================] - 52s 7ms/step - loss: 0.8617 - acc: 0.6078 - val_loss: 1.8497 - val_acc: 0.4109\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.52330\n",
      "Epoch 9/100\n",
      "7680/7680 [==============================] - 45s 6ms/step - loss: 0.8448 - acc: 0.6160 - val_loss: 1.8149 - val_acc: 0.4234\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.52330\n",
      "Epoch 10/100\n",
      "7680/7680 [==============================] - 44s 6ms/step - loss: 0.8114 - acc: 0.6372 - val_loss: 2.0698 - val_acc: 0.4156\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.52330\n",
      "Epoch 11/100\n",
      "7680/7680 [==============================] - 45s 6ms/step - loss: 0.7950 - acc: 0.6467 - val_loss: 2.0635 - val_acc: 0.4151\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.52330\n",
      "Epoch 12/100\n",
      "7680/7680 [==============================] - 45s 6ms/step - loss: 0.7704 - acc: 0.6682 - val_loss: 2.0706 - val_acc: 0.4359\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.52330\n",
      "Epoch 13/100\n",
      "7680/7680 [==============================] - 44s 6ms/step - loss: 0.7379 - acc: 0.6780 - val_loss: 2.0671 - val_acc: 0.4401\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.52330\n",
      "Epoch 14/100\n",
      "7680/7680 [==============================] - 45s 6ms/step - loss: 0.7310 - acc: 0.6895 - val_loss: 2.1013 - val_acc: 0.4422\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.52330\n",
      "Epoch 15/100\n",
      "7680/7680 [==============================] - 45s 6ms/step - loss: 0.7031 - acc: 0.6982 - val_loss: 2.0500 - val_acc: 0.4406\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.52330\n",
      "Epoch 16/100\n",
      "7680/7680 [==============================] - 44s 6ms/step - loss: 0.6898 - acc: 0.7059 - val_loss: 2.1194 - val_acc: 0.4396\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.52330\n",
      "Epoch 17/100\n",
      "7680/7680 [==============================] - 44s 6ms/step - loss: 0.6589 - acc: 0.7193 - val_loss: 2.2095 - val_acc: 0.4469\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.52330\n",
      "Epoch 18/100\n",
      "7680/7680 [==============================] - 45s 6ms/step - loss: 0.6499 - acc: 0.7257 - val_loss: 2.3458 - val_acc: 0.4479\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.52330\n",
      "Epoch 19/100\n",
      "7680/7680 [==============================] - 44s 6ms/step - loss: 0.6334 - acc: 0.7337 - val_loss: 2.2911 - val_acc: 0.4484\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.52330\n",
      "Epoch 20/100\n",
      "7680/7680 [==============================] - 45s 6ms/step - loss: 0.6177 - acc: 0.7388 - val_loss: 2.4962 - val_acc: 0.4443\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.52330\n",
      "Epoch 21/100\n",
      "7680/7680 [==============================] - 45s 6ms/step - loss: 0.6063 - acc: 0.7538 - val_loss: 2.5312 - val_acc: 0.4510\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.52330\n",
      "Epoch 22/100\n",
      "7680/7680 [==============================] - 45s 6ms/step - loss: 0.5931 - acc: 0.7527 - val_loss: 2.4701 - val_acc: 0.4484\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.52330\n",
      "Epoch 23/100\n",
      "7680/7680 [==============================] - 45s 6ms/step - loss: 0.5834 - acc: 0.7538 - val_loss: 2.5270 - val_acc: 0.4500\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.52330\n",
      "Epoch 24/100\n",
      "7680/7680 [==============================] - 45s 6ms/step - loss: 0.5729 - acc: 0.7602 - val_loss: 2.5378 - val_acc: 0.4521\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.52330\n",
      "Epoch 25/100\n",
      "7680/7680 [==============================] - 45s 6ms/step - loss: 0.5579 - acc: 0.7660 - val_loss: 2.6446 - val_acc: 0.4562\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.52330\n",
      "Epoch 26/100\n",
      "7680/7680 [==============================] - 45s 6ms/step - loss: 0.5543 - acc: 0.7655 - val_loss: 2.6680 - val_acc: 0.4500\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.52330\n",
      "Epoch 27/100\n",
      "7680/7680 [==============================] - 45s 6ms/step - loss: 0.5400 - acc: 0.7742 - val_loss: 2.6337 - val_acc: 0.4500\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.52330\n",
      "Epoch 28/100\n",
      "7680/7680 [==============================] - 48s 6ms/step - loss: 0.5294 - acc: 0.7781 - val_loss: 2.9115 - val_acc: 0.4510\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.52330\n",
      "Epoch 29/100\n",
      "7680/7680 [==============================] - 45s 6ms/step - loss: 0.5236 - acc: 0.7794 - val_loss: 2.8378 - val_acc: 0.4516\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.52330\n",
      "Epoch 30/100\n",
      "7680/7680 [==============================] - 50s 7ms/step - loss: 0.5193 - acc: 0.7828 - val_loss: 2.8628 - val_acc: 0.4531\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.52330\n",
      "Epoch 31/100\n",
      "7680/7680 [==============================] - 45s 6ms/step - loss: 0.5179 - acc: 0.7858 - val_loss: 2.8304 - val_acc: 0.4526\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.52330\n",
      "Epoch 32/100\n",
      "7680/7680 [==============================] - 45s 6ms/step - loss: 0.5034 - acc: 0.7909 - val_loss: 2.9199 - val_acc: 0.4521\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.52330\n",
      "Epoch 33/100\n",
      "7680/7680 [==============================] - 45s 6ms/step - loss: 0.4928 - acc: 0.7951 - val_loss: 2.8905 - val_acc: 0.4437\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.52330\n",
      "Epoch 34/100\n",
      "7680/7680 [==============================] - 45s 6ms/step - loss: 0.4841 - acc: 0.7965 - val_loss: 2.9991 - val_acc: 0.4427\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.52330\n",
      "Epoch 35/100\n",
      "7680/7680 [==============================] - 45s 6ms/step - loss: 0.4777 - acc: 0.7990 - val_loss: 3.0507 - val_acc: 0.4500\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.52330\n",
      "Epoch 36/100\n",
      "7680/7680 [==============================] - 45s 6ms/step - loss: 0.4861 - acc: 0.7988 - val_loss: 2.9721 - val_acc: 0.4437\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.52330\n",
      "Epoch 37/100\n",
      "7680/7680 [==============================] - 45s 6ms/step - loss: 0.4838 - acc: 0.7952 - val_loss: 2.8942 - val_acc: 0.4453\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.52330\n",
      "Epoch 38/100\n",
      "7680/7680 [==============================] - 45s 6ms/step - loss: 0.4679 - acc: 0.8013 - val_loss: 2.9661 - val_acc: 0.4526\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.52330\n",
      "Epoch 39/100\n",
      "7680/7680 [==============================] - 45s 6ms/step - loss: 0.4691 - acc: 0.8074 - val_loss: 3.0254 - val_acc: 0.4495\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.52330\n",
      "Epoch 40/100\n",
      "7680/7680 [==============================] - 45s 6ms/step - loss: 0.4496 - acc: 0.8082 - val_loss: 3.2052 - val_acc: 0.4500\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.52330\n",
      "Epoch 41/100\n",
      "7680/7680 [==============================] - 46s 6ms/step - loss: 0.4399 - acc: 0.8197 - val_loss: 3.1963 - val_acc: 0.4370\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.52330\n",
      "Epoch 42/100\n",
      "7680/7680 [==============================] - 51s 7ms/step - loss: 0.4412 - acc: 0.8163 - val_loss: 3.3182 - val_acc: 0.4516\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.52330\n",
      "Epoch 43/100\n",
      "1900/7680 [======>.......................] - ETA: 35s - loss: 0.4171 - acc: 0.8300"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-be3cb885fd00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0;31m#validation_data=(x_val, y_val),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                     callbacks=[checkpoint])#[early_stopping])\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#filepath=\"weights/weights.best.exp_16.hdf5\"\n",
    "\n",
    "#model.load_weights(filepath)\n",
    "filepath=\"weights.best.exp_OOV.hdf5\"\n",
    "\n",
    "#saved_model = filepath\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "callbacks_list = [checkpoint,early_stopping]\n",
    "history = model.fit(input_train, y_train,\n",
    "                    epochs=100,\n",
    "                    batch_size=50,\n",
    "                    #validation_data=(x_val, y_val),\n",
    "                    validation_split= 0.2,\n",
    "                    callbacks=[checkpoint])#[early_stopping])\n",
    "\n",
    "\n",
    "model.save_weights(filepath)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 'Testing And Evalaution'\n",
    "1- classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 18.33%\n"
     ]
    }
   ],
   "source": [
    "def plot_show(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "#plot_show(history)\n",
    "#filepath=\"weights/weights.best.exp16.hdf5\"\n",
    "\n",
    "model.load_weights(filepath)\n",
    "#y_test.argmax(axis=1), predicte.argmax(axis=1)\n",
    "scores= model.evaluate(input_test, y_test,verbose=0)\n",
    "predicte = model.predict(input_test, verbose = 2, batch_size = batch_size)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "\n",
    "\n",
    "\n",
    "#from keras.utils.vis_utils import plot_model\n",
    "#plot_model(model, to_file=filepath+'.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.21      0.19       200\n",
      "           1       0.20      0.34      0.25       200\n",
      "           2       0.21      0.20      0.20       200\n",
      "           3       0.14      0.14      0.14       200\n",
      "           4       0.16      0.14      0.15       200\n",
      "           5       0.23      0.07      0.11       200\n",
      "\n",
      "   micro avg       0.18      0.18      0.18      1200\n",
      "   macro avg       0.19      0.18      0.18      1200\n",
      "weighted avg       0.19      0.18      0.18      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test and Evaluation\n",
    "#model.load_weights(filepath)\n",
    "#predicted = model.predict_proba(input_test, verbose = 2, batch_size = batch_size)\n",
    "#for binary\n",
    "#print(predicte)\n",
    "#print(metrics.classification_report(y_test, np.round(predicte)))\n",
    "#for multi-class\n",
    "print(metrics.classification_report(y_test.argmax(axis=1), predicte.argmax(axis=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18333333333333332\n",
      "Accuracy: 18.33%\n",
      "[[42 60 29 35 27  7]\n",
      " [37 68 26 40 17 12]\n",
      " [46 36 39 37 36  6]\n",
      " [33 61 33 29 29 15]\n",
      " [41 57 32 33 27 10]\n",
      " [45 54 23 27 36 15]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#predicted = np.argmax(predicted, axis=1)\n",
    "#scores= model.evaluate(input_test, y_test,verbose=0)\n",
    "#for binary\n",
    "#print(metrics.accuracy_score(y_test, np.round(predicte)))\n",
    "#conf_mat = metrics.confusion_matrix(y_test, np.round(predicte))\n",
    "#for multi\n",
    "print(metrics.accuracy_score(y_test.argmax(axis=1), predicte.argmax(axis=1)))\n",
    "conf_mat = metrics.confusion_matrix(y_test.argmax(axis=1), predicte.argmax(axis=1))\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "print(conf_mat)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "            xticklabels=['negative','positive','no'], yticklabels=['negative','positive','no'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n",
    "#for x,y,p in zip(input_test,y_test,predicte):\n",
    " #   print(x,y,p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_convnet(max_features, vectore_d):\n",
    "    input_shape = Input(shape=(max_features, vectore_d))\n",
    "    tower_1 = Conv1D(64, 3, activation='relu')(input_shape)\n",
    "    tower_1 = MaxPooling1D(5)(tower_1)\n",
    "   # tower_1 = Flatten()(tower_1)\n",
    "\n",
    "    tower_2 = Conv1D(64, 4, activation='relu')(input_shape)\n",
    "    tower_2 = MaxPooling1D(4)(tower_2)\n",
    "    #tower_2 = Flatten()(tower_2)\n",
    "\n",
    "    tower_3 = Conv1D(64, 5, activation='relu')(input_shape)\n",
    "    tower_3 = MaxPooling1D(3)(tower_3)\n",
    "    #tower_3 = Flatten()(tower_3)\n",
    "    \n",
    "    tower_4 = LSTM(64,dropout=0.5, recurrent_dropout=0.5, return_sequences = True)(input_shape)\n",
    "    tower_5 = LSTM(32,dropout=0.5, recurrent_dropout=0.5,return_sequences= False)(tower_4)\n",
    "    #tower_4 = Dense(100, activation = 'relu')(tower_4)\n",
    "    \n",
    "    \n",
    "    \n",
    "    merged = layers.concatenate([tower_1, tower_2,tower_3], axis=1)\n",
    "    merged = Flatten()(merged)\n",
    "    \n",
    "    final_merged = layers.concatenate([merged,tower_5],axis = 1)\n",
    "    out = Dense(100,activation='relu')(final_merged)\n",
    "    #out = Dropout(0.3)(out)\n",
    "    out = Dense(30)(out)\n",
    "    out = Dense(1, activation='sigmoid')(out)\n",
    "\n",
    "    model = Model(input_shape, out)\n",
    "    print(model.summary())\n",
    "    from keras.utils.vis_utils import plot_model\n",
    "    plot_model(model, to_file='weights/1CNN.png', show_shapes=True, show_layer_names=True)\n",
    "    \n",
    "    return model\n",
    "create_convnet(max_features, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
